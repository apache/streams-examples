{"paragraphs":[{"title":"","text":"import org.apache.streams.config._\nimport org.apache.streams.core._\nimport org.apache.youtube.pojo._\n\nimport com.typesafe.config._\nimport com.youtube.provider._\n\nimport java.util.Iterator","user":"anonymous","dateUpdated":"2016-11-19T00:38:54-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141061_-630532021","id":"20161115-182904_1821687700","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.streams.config._\n\nimport org.apache.streams.core._\n\nimport org.apache.youtube.pojo._\n\nimport com.typesafe.config._\n\nimport com.youtube.provider._\n\nimport java.util.Iterator\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-19T00:39:23-0600","dateFinished":"2016-11-19T00:39:28-0600","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:249"},{"title":"","text":"%sh\ncurl \"http://people.apache.org/~sblackmon/streams-c84fa47bd759.p12\" -o /tmp/streams-c84fa47bd759.p12\n","user":"anonymous","dateUpdated":"2016-11-18T23:55:53-0600","config":{"colWidth":12,"editorMode":"ace/mode/sh","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479495810678_979281971","id":"20161118-200330_292837422","result":{"code":"SUCCESS","type":"TEXT","msg":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2476  100  2476    0     0  22831      0 --:--:-- --:--:-- --:--:-- 22925\n"},"dateCreated":"2016-11-18T20:03:30-0600","dateStarted":"2016-11-18T23:56:23-0600","dateFinished":"2016-11-18T23:56:24-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:250"},{"title":"Build 'hocon', the Apache Streams Config","text":"%spark\n\nval apiKey = z.input(\"apiKey\", \"\")\nval serviceAccountEmailAddress = z.input(\"serviceAccountEmailAddress\", \"\")\nval pathToP12KeyFile = z.input(\"pathToP12KeyFile\", \"\")\n\nval credentials_hocon = s\"\"\"\nyoutube {\n  apiKey = $apiKey\n  oauth {\n    serviceAccountEmailAddress = \"$serviceAccountEmailAddress\"\n    pathToP12KeyFile = \"$pathToP12KeyFile\"\n  }\n}\n\"\"\"\n","user":"anonymous","dateUpdated":"2016-11-19T00:40:04-0600","config":{"tableHide":true,"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"map":{"baseMapType":"Streets","isOnline":true,"pinCols":[]},"height":300},"enabled":true},"settings":{"params":{"ApiKey":"79d9f9ca2796d1ec5334faf8d6efaa6456a297e6","apiKey":"79d9f9ca2796d1ec5334faf8d6efaa6456a297e6","Username":"rawkintrevo","ConsumerKey":"hWqUTYi6kKbsfSFiTdz5Wqel0","AccessToken":"1566016094-0YgzZ5Aw0lXMD4BWpEAkPAxOpWneMLnQx3Mxif8","ConsumerSecret":"hQnLRoenyOHrtJQYLfrB5vbOBhidLsg0vLspmWZDN5MF0wkMwP","AccessTokenSecret":"1SpRe7ZdnTVUrLfq0LPT1nSlJb64N7wT0JTZM8blDq8kD","pathToP12KeyFile":"/tmp/streams-c84fa47bd759.p12","userId":"UCLDJ_V9KUOdOFSbDvPfGBxw","serviceAccountEmailAddress":"streamsdev@adroit-particle-764.iam.gserviceaccount.com"},"forms":{"apiKey":{"name":"apiKey","displayName":"apiKey","type":"input","defaultValue":"","hidden":false},"serviceAccountEmailAddress":{"name":"serviceAccountEmailAddress","displayName":"serviceAccountEmailAddress","type":"input","defaultValue":"","hidden":false},"pathToP12KeyFile":{"name":"pathToP12KeyFile","displayName":"pathToP12KeyFile","type":"input","defaultValue":"","hidden":false}}},"apps":[],"jobName":"paragraph_1479492141063_-629762524","id":"20161023-191342_1492908722","result":{"code":"SUCCESS","type":"TEXT","msg":"\napiKey: Object = 79d9f9ca2796d1ec5334faf8d6efaa6456a297e6\n\nserviceAccountEmailAddress: Object = streamsdev@adroit-particle-764.iam.gserviceaccount.com\n\npathToP12KeyFile: Object = /tmp/streams-c84fa47bd759.p12\n\n\n\n\n\n\n\n\n\n\ncredentials_hocon: String = \n\"\nyoutube {\n  apiKey = 79d9f9ca2796d1ec5334faf8d6efaa6456a297e6\n  oauth {\n    serviceAccountEmailAddress = \"streamsdev@adroit-particle-764.iam.gserviceaccount.com\"\n    pathToP12KeyFile = \"/tmp/streams-c84fa47bd759.p12\"\n  }\n}\n\"\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:56:53-0600","dateFinished":"2016-11-18T23:56:54-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:251"},{"title":"","text":"%spark\nval accounts_hocon = s\"\"\"\nyoutube.youtubeUsers = [\n    # Apache Software Foundation - Topic\n    { userId = \"UCegQNPmRCAJvCq6JfHUKZ9A\"},\n    # Apache Software Foundation\n    { userId = \"TheApacheFoundation\"},\n    # Apache Spark \n    { userId = \"TheApacheSpark\" },\n    # Apache Spark - Topic\n    { userId = \"UCwhtqOdWyCuqOboj-E1bpFQ\"},\n    # Apache Flink Berlin\n    { userId = \"UCY8_lgiZLZErZPF47a2hXMA\"},\n    # Apache Syncope\n    { userId = \"UCkrSQVb5Qzb13crS1kCOiQQ\"},\n    # Apache Accumulo\n    { userId = \"apacheaccumulo\"},\n    # Apache Hive - Topic\n    { userId = \"UCIjbkZAX5VlvSKoSzNUHIoQ\"},\n    # Apache HBase - Topic\n    { userId = \"UCcGNHRiO9bi6BeH5OdhY2Kw\"},\n    # Apache Cassandra - Topic\n    { userId = \"UC6nsS04n_wBpCDXqSAkFM-w\"},\n    # Apache Hadoop - Topic\n    { userId = \"UCgRu3LbCjczooTVI9VSvstg\"},\n    # Apache Avro - Topic\n    { userId = \"UCzHCk8Gl5eP85xz0HwXjkzw\"},\n    # Apache Maven - Topic\n    { userId = \"UCBS2s2cwx-MW9rVeKwee_VA\"},  \n    # Apache Oozie - Topic\n    { userId = \"UCRyBrviuu3qMNliolYXvC0g\"}, \n  ]\n\"\"\"","user":"anonymous","dateUpdated":"2016-11-19T00:40:18-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141063_-629762524","id":"20161115-175550_1569899821","result":{"code":"SUCCESS","type":"TEXT","msg":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naccounts_hocon: String = \n\"\nyoutube.youtubeUsers = [\n    # Apache Software Foundation - Topic\n    { userId = \"UCegQNPmRCAJvCq6JfHUKZ9A\"},\n    # Apache Software Foundation\n    { userId = \"TheApacheFoundation\"},\n    # Apache Spark \n    { userId = \"TheApacheSpark\" },\n    # Apache Spark - Topic\n    { userId = \"UCwhtqOdWyCuqOboj-E1bpFQ\"},\n    # Apache Flink Berlin\n    { userId = \"UCY8_lgiZLZErZPF47a2hXMA\"},\n    # Apache Syncope\n    { userId = \"UCkrSQVb5Qzb13crS1kCOiQQ\"},\n    # Apache Accumulo\n    { userId = \"apacheaccumulo\"},\n    # Apache Hive - Topic\n    { userId = \"UCIjbkZAX5VlvSKoSzNUHIoQ\"},\n    # Apache HBase - Topic\n    { userId = \"UCcGNHRiO9bi6BeH5OdhY2Kw\"},\n    # Apache Cassandra - Topic\n    { userId = \"UC6nsS04n_wBpCDXqSAkFM-w\"},\n    # Apache Hadoop - Topic\n    { userId = \"UCgRu3LbCj..."},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:57:23-0600","dateFinished":"2016-11-18T23:57:24-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:252"},{"title":"","text":"%spark\nval reference = ConfigFactory.load()\nval credentials = ConfigFactory.parseString(credentials_hocon)\nval accounts = ConfigFactory.parseString(accounts_hocon)\nval typesafe = accounts.withFallback(credentials).withFallback(reference).resolve()\nval youtubeConfiguration = new ComponentConfigurator(classOf[YoutubeConfiguration]).detectConfiguration(typesafe, \"youtube\");\n","user":"anonymous","dateUpdated":"2016-11-19T00:41:15-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141063_-629762524","id":"20161115-182824_268335435","result":{"code":"SUCCESS","type":"TEXT","msg":"reference: com.typesafe.config.Config = Config(SimpleConfigObject({\"akka\":{\"actor\":{\"creation-timeout\":\"20s\",\"debug\":{\"autoreceive\":\"off\",\"event-stream\":\"off\",\"fsm\":\"off\",\"lifecycle\":\"off\",\"receive\":\"off\",\"router-misconfiguration\":\"off\",\"unhandled\":\"off\"},\"default-dispatcher\":{\"attempt-teamwork\":\"on\",\"default-executor\":{\"fallback\":\"fork-join-executor\"},\"executor\":\"default-executor\",\"fork-join-executor\":{\"parallelism-factor\":3,\"parallelism-max\":64,\"parallelism-min\":8,\"task-peeking-mode\":\"FIFO\"},\"mailbox-requirement\":\"\",\"shutdown-timeout\":\"1s\",\"thread-pool-executor\":{\"allow-core-timeout\":\"on\",\"core-pool-size-factor\":3,\"core-pool-size-max\":64,\"core-pool-size-min\":8,\"keep-alive-time\":\"60s\",\"max-pool-size-factor\":3,\"max-pool-size-max\":64,\"max-pool-size-min\":8,\"task-queue-size\":-1,\"task-queue...\ncredentials: com.typesafe.config.Config = Config(SimpleConfigObject({\"youtube\":{\"apiKey\":\"79d9f9ca2796d1ec5334faf8d6efaa6456a297e6\",\"oauth\":{\"pathToP12KeyFile\":\"/tmp/streams-c84fa47bd759.p12\",\"serviceAccountEmailAddress\":\"streamsdev@adroit-particle-764.iam.gserviceaccount.com\"}}}))\n\naccounts: com.typesafe.config.Config = Config(SimpleConfigObject({\"youtube\":{\"youtubeUsers\":[{\"userId\":\"UCegQNPmRCAJvCq6JfHUKZ9A\"},{\"userId\":\"TheApacheFoundation\"},{\"userId\":\"TheApacheSpark\"},{\"userId\":\"UCwhtqOdWyCuqOboj-E1bpFQ\"},{\"userId\":\"UCY8_lgiZLZErZPF47a2hXMA\"},{\"userId\":\"UCkrSQVb5Qzb13crS1kCOiQQ\"},{\"userId\":\"apacheaccumulo\"},{\"userId\":\"UCIjbkZAX5VlvSKoSzNUHIoQ\"},{\"userId\":\"UCcGNHRiO9bi6BeH5OdhY2Kw\"},{\"userId\":\"UC6nsS04n_wBpCDXqSAkFM-w\"},{\"userId\":\"UCgRu3LbCjczooTVI9VSvstg\"},{\"userId\":\"UCzHCk8Gl5eP85xz0HwXjkzw\"},{\"userId\":\"UCBS2s2cwx-MW9rVeKwee_VA\"},{\"userId\":\"UCRyBrviuu3qMNliolYXvC0g\"}]}}))\ntypesafe: com.typesafe.config.Config = Config(SimpleConfigObject({\"akka\":{\"actor\":{\"creation-timeout\":\"20s\",\"debug\":{\"autoreceive\":\"off\",\"event-stream\":\"off\",\"fsm\":\"off\",\"lifecycle\":\"off\",\"receive\":\"off\",\"router-misconfiguration\":\"off\",\"unhandled\":\"off\"},\"default-dispatcher\":{\"attempt-teamwork\":\"on\",\"default-executor\":{\"fallback\":\"fork-join-executor\"},\"executor\":\"default-executor\",\"fork-join-executor\":{\"parallelism-factor\":3,\"parallelism-max\":64,\"parallelism-min\":8,\"task-peeking-mode\":\"FIFO\"},\"mailbox-requirement\":\"\",\"shutdown-timeout\":\"1s\",\"thread-pool-executor\":{\"allow-core-timeout\":\"on\",\"core-pool-size-factor\":3,\"core-pool-size-max\":64,\"core-pool-size-min\":8,\"keep-alive-time\":\"60s\",\"max-pool-size-factor\":3,\"max-pool-size-max\":64,\"max-pool-size-min\":8,\"task-queue-size\":-1,\"task-queue-...youtubeConfiguration: org.apache.youtube.pojo.YoutubeConfiguration = org.apache.youtube.pojo.YoutubeConfiguration@68306350[protocol=<null>,host=<null>,port=<null>,version=<null>,endpoint=<null>,apiKey=79d9f9ca2796d1ec5334faf8d6efaa6456a297e6,follow=[],youtubeUsers=[org.apache.streams.google.gplus.configuration.UserInfo@1167717a[userId=UCegQNPmRCAJvCq6JfHUKZ9A,afterDate=<null>,beforeDate=<null>,additionalProperties={}], org.apache.streams.google.gplus.configuration.UserInfo@113f6c3c[userId=TheApacheFoundation,afterDate=<null>,beforeDate=<null>,additionalProperties={}], org.apache.streams.google.gplus.configuration.UserInfo@38860dc2[userId=TheApacheSpark,afterDate=<null>,beforeDate=<null>,additionalProperties={}], org.apache.streams.google.gplus.configuration.UserInfo@53c7c361[userId=UCwh..."},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:57:26-0600","dateFinished":"2016-11-18T23:57:26-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:253"},{"title":"","text":"%spark\n// Pull info on those channels\nval YoutubeChannelProvider = new YoutubeChannelProvider(youtubeConfiguration);\nYoutubeChannelProvider.prepare(null)\nYoutubeChannelProvider.startStream()\n//\nval channel_buf = scala.collection.mutable.ArrayBuffer.empty[Object]\nwhile(YoutubeChannelProvider.isRunning()) {\n  val resultSet = YoutubeChannelProvider.readCurrent()\n  resultSet.size()\n  val iterator = resultSet.iterator();\n  while(iterator.hasNext()) {\n    val datum = iterator.next();\n    channel_buf += datum.getDocument\n  }\n}\nchannel_buf.size","user":"anonymous","dateUpdated":"2016-11-18T23:57:26-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141064_-631686268","id":"20161115-183815_254751684","result":{"code":"SUCCESS","type":"TEXT","msg":"\nYoutubeChannelProvider: com.youtube.provider.YoutubeChannelProvider = com.youtube.provider.YoutubeChannelProvider@66a858f6\n\nchannel_buf: scala.collection.mutable.ArrayBuffer[Object] = ArrayBuffer()\n\nres5: Int = 11\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:57:28-0600","dateFinished":"2016-11-18T23:57:31-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:254"},{"title":"","text":"%spark\nimport com.typesafe.config._\nimport org.apache.streams.config._\nimport org.apache.streams.core._\nimport com.youtube.provider._\nimport org.apache.youtube.pojo._\nimport java.util.Iterator\n\nval buf = scala.collection.mutable.ArrayBuffer.empty[Object]\n\nval provider = new YoutubeUserActivityProvider(youtubeConfiguration);\nprovider.prepare(null)\nprovider.startStream()\nwhile(provider.isRunning()) {\n    val resultSet = provider.readCurrent()\n    resultSet.size()\n    val iterator = resultSet.iterator();\n    while(iterator.hasNext()) {\n        val datum = iterator.next();\n        //println(datum.getDocument)\n        buf += datum.getDocument\n    }   \n}\nbuf.size","user":"anonymous","dateUpdated":"2016-11-18T23:57:28-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"map":{"baseMapType":"Streets","isOnline":true,"pinCols":[]},"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141064_-631686268","id":"20161025-184115_-1493939533","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport com.typesafe.config._\n\nimport org.apache.streams.config._\n\nimport org.apache.streams.core._\n\nimport com.youtube.provider._\n\nimport org.apache.youtube.pojo._\n\nimport java.util.Iterator\n\nbuf: scala.collection.mutable.ArrayBuffer[Object] = ArrayBuffer()\n\nprovider: com.youtube.provider.YoutubeUserActivityProvider = com.youtube.provider.YoutubeUserActivityProvider@716e2d23\n\nres9: Int = 105\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:57:58-0600","dateFinished":"2016-11-18T23:58:19-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:255"},{"title":"","text":"%spark\nimport org.apache.streams.core.StreamsDatum\nimport com.youtube.processor._\nimport scala.collection.JavaConversions._\n//Normalize activities -> posts(s)\nval YoutubeTypeConverter = new YoutubeTypeConverter()\nYoutubeTypeConverter.prepare()\n\nval pages_datums = channel_buf.flatMap(x => YoutubeTypeConverter.process(new StreamsDatum(x)))","user":"anonymous","dateUpdated":"2016-11-18T23:57:58-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141064_-631686268","id":"20161115-183950_1113670086","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.streams.core.StreamsDatum\n\nimport com.youtube.processor._\n\nimport scala.collection.JavaConversions._\n\nYoutubeTypeConverter: com.youtube.processor.YoutubeTypeConverter = com.youtube.processor.YoutubeTypeConverter@4b7c31de\n\npages_datums: scala.collection.mutable.ArrayBuffer[org.apache.streams.core.StreamsDatum] = \nArrayBuffer(StreamsDatum{timestamp=null, sequenceid=null, metadata={}, document=org.apache.streams.pojo.json.Activity@49a39cca[id=<null>,actor=org.apache.streams.pojo.json.ActivityObject@72546de2[id=id:youtube:UCY8_lgiZLZErZPF47a2hXMA,image=org.apache.streams.pojo.json.Image@22c5896[additionalProperties={},duration=<null>,height=<null>,width=<null>,url=https://yt3.ggpht.com/--4Lc7k3cP0Y/AAAAAAAAAAI/AAAAAAAAAAA/yFaYqbejnvY/s240-c-k-no-mo-rj-c0xffffff/photo.jpg,additionalProperties={}],displayName=Apache Flink Berlin,summary=Apache Flink is a programming environment and distributed runtime that makes it easy for developers to build batch and streaming data applications. Flink offers familiar fluent..."},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:58:13-0600","dateFinished":"2016-11-18T23:58:21-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:256"},{"title":"","text":"%spark\nimport org.apache.streams.jackson.StreamsJacksonMapper;\nimport sqlContext._\nimport sqlContext.implicits._\n\nval mapper = StreamsJacksonMapper.getInstance();\nval pages_jsons = pages_datums.map(o => mapper.writeValueAsString(o.getDocument))\nval pagesRDD = sc.parallelize(pages_jsons)\n\nval pagesDF = sqlContext.read.json(pagesRDD)\n\nval cleanDF = pagesDF.withColumn(\"summary\", removePunctuationAndSpecialChar(pagesDF(\"actor.summary\")))\ncleanDF.registerTempTable(\"youtube_pages\")\ncleanDF.printSchema","user":"anonymous","dateUpdated":"2016-11-18T23:58:13-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141064_-631686268","id":"20161115-183944_1706309463","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.streams.jackson.StreamsJacksonMapper\n\nimport sqlContext._\n\nimport sqlContext.implicits._\n\nmapper: org.apache.streams.jackson.StreamsJacksonMapper = org.apache.streams.jackson.StreamsJacksonMapper@7efe1ed4\npages_jsons: scala.collection.mutable.ArrayBuffer[String] = ArrayBuffer({\"actor\":{\"id\":\"id:youtube:UCY8_lgiZLZErZPF47a2hXMA\",\"image\":{\"url\":\"https://yt3.ggpht.com/--4Lc7k3cP0Y/AAAAAAAAAAI/AAAAAAAAAAA/yFaYqbejnvY/s240-c-k-no-mo-rj-c0xffffff/photo.jpg\"},\"displayName\":\"Apache Flink Berlin\",\"summary\":\"Apache Flink is a programming environment and distributed runtime that makes it easy for developers to build batch and streaming data applications. Flink offers familiar fluent programming APIs and a set of libraries, and backs these APIs with a robust and hybrid execution engine that unifies stream and batch processing. Flink entered the Apache Incubator in April 2014, and graduated in December 2014.\\n\\n\\nBe sure to check out www.flink-forward.org \\nFlink Forward 2015 is the first conference ...\npagesRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:90\npagesDF: org.apache.spark.sql.DataFrame = [actor: struct<displayName:string,extensions:struct<followers:bigint,posts:bigint>,id:string,image:struct<url:string>,summary:string,url:string>, extensions: struct<youtube:struct<contentDetails:struct<relatedPlaylists:struct<uploads:string>>,etag:string,id:string,kind:string,snippet:struct<description:string,localized:struct<description:string,title:string>,publishedAt:struct<dateOnly:boolean,timeZoneShift:bigint,value:bigint>,thumbnails:struct<default:struct<url:string>,high:struct<url:string>,medium:struct<url:string>>,title:string>,statistics:struct<commentCount:bigint,hiddenSubscriberCount:boolean,subscriberCount:bigint,videoCount:bigint,viewCount:bigint>,topicDetails:struct<topicIds:array<string>>>>, provider: struct<displayName:string,id:...cleanDF: org.apache.spark.sql.DataFrame = [actor: struct<displayName:string,extensions:struct<followers:bigint,posts:bigint>,id:string,image:struct<url:string>,summary:string,url:string>, extensions: struct<youtube:struct<contentDetails:struct<relatedPlaylists:struct<uploads:string>>,etag:string,id:string,kind:string,snippet:struct<description:string,localized:struct<description:string,title:string>,publishedAt:struct<dateOnly:boolean,timeZoneShift:bigint,value:bigint>,thumbnails:struct<default:struct<url:string>,high:struct<url:string>,medium:struct<url:string>>,title:string>,statistics:struct<commentCount:bigint,hiddenSubscriberCount:boolean,subscriberCount:bigint,videoCount:bigint,viewCount:bigint>,topicDetails:struct<topicIds:array<string>>>>, provider: struct<displayName:string,id:...root\n |-- actor: struct (nullable = true)\n |    |-- displayName: string (nullable = true)\n |    |-- extensions: struct (nullable = true)\n |    |    |-- followers: long (nullable = true)\n |    |    |-- posts: long (nullable = true)\n |    |-- id: string (nullable = true)\n |    |-- image: struct (nullable = true)\n |    |    |-- url: string (nullable = true)\n |    |-- summary: string (nullable = true)\n |    |-- url: string (nullable = true)\n |-- extensions: struct (nullable = true)\n |    |-- youtube: struct (nullable = true)\n |    |    |-- contentDetails: struct (nullable = true)\n |    |    |    |-- relatedPlaylists: struct (nullable = true)\n |    |    |    |    |-- uploads: string (nullable = true)\n |    |    |-- etag: string (nullable = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- kind: string (nullable = true)\n |    |    |-- snippet: struct (nullable = true)\n |    |    |    |-- description: string (nullable = true)\n |    |    |    |-- localized: struct (nullable = true)\n |    |    |    |    |-- description: string (nullable = true)\n |    |    |    |    |-- title: string (nullable = true)\n |    |    |    |-- publishedAt: struct (nullable = true)\n |    |    |    |    |-- dateOnly: boolean (nullable = true)\n |    |    |    |    |-- timeZoneShift: long (nullable = true)\n |    |    |    |    |-- value: long (nullable = true)\n |    |    |    |-- thumbnails: struct (nullable = true)\n |    |    |    |    |-- default: struct (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- high: struct (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- medium: struct (nullable = true)\n |    |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |-- title: string (nullable = true)\n |    |    |-- statistics: struct (nullable = true)\n |    |    |    |-- commentCount: long (nullable = true)\n |    |    |    |-- hiddenSubscriberCount: boolean (nullable = true)\n |    |    |    |-- subscriberCount: long (nullable = true)\n |    |    |    |-- videoCount: long (nullable = true)\n |    |    |    |-- viewCount: long (nullable = true)\n |    |    |-- topicDetails: struct (nullable = true)\n |    |    |    |-- topicIds: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |-- provider: struct (nullable = true)\n |    |-- displayName: string (nullable = true)\n |    |-- id: string (nullable = true)\n |-- verb: string (nullable = true)\n |-- summary: string (nullable = true)\n\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:58:37-0600","dateFinished":"2016-11-18T23:58:42-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:257"},{"title":"","text":"%spark\nimport org.apache.streams.core.StreamsDatum\nimport com.youtube.processor._\nimport scala.collection.JavaConversions._\n//Normalize activities -> posts(s)\nval YoutubeTypeConverter = new YoutubeTypeConverter()\nYoutubeTypeConverter.prepare()\n\nval useractivity_posts = buf.flatMap(x => YoutubeTypeConverter.process(new StreamsDatum(x)))\n","user":"anonymous","dateUpdated":"2016-11-18T23:58:37-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"map":{"baseMapType":"Streets","isOnline":true,"pinCols":[]},"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141065_-632071017","id":"20161023-191634_-1435819396","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.streams.core.StreamsDatum\n\nimport com.youtube.processor._\n\nimport scala.collection.JavaConversions._\n\nYoutubeTypeConverter: com.youtube.processor.YoutubeTypeConverter = com.youtube.processor.YoutubeTypeConverter@10b70836\n\nuseractivity_posts: scala.collection.mutable.ArrayBuffer[org.apache.streams.core.StreamsDatum] = \nArrayBuffer(StreamsDatum{timestamp=null, sequenceid=null, metadata={}, document=org.apache.streams.pojo.json.Activity@15aba843[id=id:youtube:post:RYoFwQFvC_g,actor=org.apache.streams.pojo.json.ActivityObject@4bd9a25c[id=id:youtube:UCY8_lgiZLZErZPF47a2hXMA,image=<null>,displayName=Apache Flink Berlin,summary=Two days of conference. One day of training. More than 350 attendees from all over the globe, over 40 international speakers, 3 stages and lots of squirrels – At Flink Forward Berlin we’ve enjoyed three days full of exciting training sessions, keynotes, technical talks and panels. It was the second Flink Forward organized by data Artisans and we want to thank you for trusting us and maki..."},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:58:57-0600","dateFinished":"2016-11-18T23:58:59-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:258"},{"title":"","text":"%spark\nimport org.apache.streams.jackson.StreamsJacksonMapper;\nimport sqlContext._\nimport sqlContext.implicits._\n\nval mapper = StreamsJacksonMapper.getInstance();\nval jsons = useractivity_posts.map(o => mapper.writeValueAsString(o.getDocument))\nval activitiesRDD = sc.parallelize(jsons)\n\nval activitiesDF = sqlContext.read.json(activitiesRDD)\n\nval cleanDF = activitiesDF.withColumn(\"content\", removePunctuationAndSpecialChar(activitiesDF(\"content\")))\ncleanDF.registerTempTable(\"youtube_posts\")\ncleanDF.printSchema","user":"anonymous","dateUpdated":"2016-11-18T23:58:57-0600","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"map":{"baseMapType":"Streets","isOnline":true,"pinCols":[]},"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141066_-630916770","id":"20161023-191819_1405823231","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.streams.jackson.StreamsJacksonMapper\n\nimport sqlContext._\n\nimport sqlContext.implicits._\n\nmapper: org.apache.streams.jackson.StreamsJacksonMapper = org.apache.streams.jackson.StreamsJacksonMapper@7efe1ed4\njsons: scala.collection.mutable.ArrayBuffer[String] = ArrayBuffer({\"id\":\"id:youtube:post:RYoFwQFvC_g\",\"actor\":{\"id\":\"id:youtube:UCY8_lgiZLZErZPF47a2hXMA\",\"displayName\":\"Apache Flink Berlin\",\"summary\":\"Two days of conference. One day of training. More than 350 attendees from all over the globe, over 40 international speakers, 3 stages and lots of squirrels – At Flink Forward Berlin we’ve enjoyed three days full of exciting training sessions, keynotes, technical talks and panels. It was the second Flink Forward organized by data Artisans and we want to thank you for trusting us and making next year’s conferences in San Francisco and Berlin a blast.\\n\\ndroidcon Berlin – http://droidcon.de\\nFacebook: https://www.facebook.com/dr...\\nGoogle+: https://plus.google.com/+dr...\\nTwitter: https://t...\nactivitiesRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[6] at parallelize at <console>:104\n\nactivitiesDF: org.apache.spark.sql.DataFrame = [actor: struct<displayName:string,handle:string,id:string,summary:string>, content: string, id: string, likes: struct<count:bigint>, object: struct<image:struct<height:bigint,url:string,width:bigint>,objectType:string,url:string>, provider: struct<displayName:string,id:string>, published: string, title: string, url: string, verb: string, youtube: struct<etag:string,id:string,kind:string,snippet:struct<channelId:string,channelTitle:string,description:string,publishedAt:struct<dateOnly:boolean,timeZoneShift:bigint,value:bigint>,thumbnails:struct<default:struct<height:bigint,url:string,width:bigint>>,title:string>,statistics:struct<commentCount:bigint,dislikeCount:bigint,favoriteCount:bigint,likeCount:bigint,viewCount:bigint>>]\n\ncleanDF: org.apache.spark.sql.DataFrame = [actor: struct<displayName:string,handle:string,id:string,summary:string>, content: string, id: string, likes: struct<count:bigint>, object: struct<image:struct<height:bigint,url:string,width:bigint>,objectType:string,url:string>, provider: struct<displayName:string,id:string>, published: string, title: string, url: string, verb: string, youtube: struct<etag:string,id:string,kind:string,snippet:struct<channelId:string,channelTitle:string,description:string,publishedAt:struct<dateOnly:boolean,timeZoneShift:bigint,value:bigint>,thumbnails:struct<default:struct<height:bigint,url:string,width:bigint>>,title:string>,statistics:struct<commentCount:bigint,dislikeCount:bigint,favoriteCount:bigint,likeCount:bigint,viewCount:bigint>>]\nroot\n |-- actor: struct (nullable = true)\n |    |-- displayName: string (nullable = true)\n |    |-- handle: string (nullable = true)\n |    |-- id: string (nullable = true)\n |    |-- summary: string (nullable = true)\n |-- content: string (nullable = true)\n |-- id: string (nullable = true)\n |-- likes: struct (nullable = true)\n |    |-- count: long (nullable = true)\n |-- object: struct (nullable = true)\n |    |-- image: struct (nullable = true)\n |    |    |-- height: long (nullable = true)\n |    |    |-- url: string (nullable = true)\n |    |    |-- width: long (nullable = true)\n |    |-- objectType: string (nullable = true)\n |    |-- url: string (nullable = true)\n |-- provider: struct (nullable = true)\n |    |-- displayName: string (nullable = true)\n |    |-- id: string (nullable = true)\n |-- published: string (nullable = true)\n |-- title: string (nullable = true)\n |-- url: string (nullable = true)\n |-- verb: string (nullable = true)\n |-- youtube: struct (nullable = true)\n |    |-- etag: string (nullable = true)\n |    |-- id: string (nullable = true)\n |    |-- kind: string (nullable = true)\n |    |-- snippet: struct (nullable = true)\n |    |    |-- channelId: string (nullable = true)\n |    |    |-- channelTitle: string (nullable = true)\n |    |    |-- description: string (nullable = true)\n |    |    |-- publishedAt: struct (nullable = true)\n |    |    |    |-- dateOnly: boolean (nullable = true)\n |    |    |    |-- timeZoneShift: long (nullable = true)\n |    |    |    |-- value: long (nullable = true)\n |    |    |-- thumbnails: struct (nullable = true)\n |    |    |    |-- default: struct (nullable = true)\n |    |    |    |    |-- height: long (nullable = true)\n |    |    |    |    |-- url: string (nullable = true)\n |    |    |    |    |-- width: long (nullable = true)\n |    |    |-- title: string (nullable = true)\n |    |-- statistics: struct (nullable = true)\n |    |    |-- commentCount: long (nullable = true)\n |    |    |-- dislikeCount: long (nullable = true)\n |    |    |-- favoriteCount: long (nullable = true)\n |    |    |-- likeCount: long (nullable = true)\n |    |    |-- viewCount: long (nullable = true)\n\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:59:17-0600","dateFinished":"2016-11-18T23:59:22-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:259"},{"title":"","text":"%spark.sql\nselect actor.id, actor.displayName, summary, actor.extensions.followers, actor.extensions.posts from youtube_pages","user":"anonymous","dateUpdated":"2016-11-18T23:59:17-0600","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","optionOpen":false,"keys":[{"name":"id","index":0,"aggr":"sum"}],"values":[{"name":"displayName","index":1,"aggr":"sum"}],"scatter":{"yAxis":{"name":"displayName","index":1,"aggr":"sum"},"xAxis":{"name":"id","index":0,"aggr":"sum"}},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141066_-630916770","id":"20161115-184113_720380817","result":{"code":"SUCCESS","type":"TABLE","msg":"id\tdisplayName\tsummary\tfollowers\tposts\nid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink is a programming environment and distributed runtime that makes it easy for developers to build batch and streaming data applications Flink offers familiar fluent programming APIs and a set of libraries and backs these APIs with a robust and hybrid execution engine that unifies stream and batch processing Flink entered the Apache Incubator in April 2014 and graduated in December 2014 Be sure to check out www flink forward org Flink Forward 2015 is the first conference to bring together the Apache Flink developer and user community\t662\t127\nid:youtube:UCegQNPmRCAJvCq6JfHUKZ9A\tApache Software Foundation - Topic\tThe Apache Software Foundation əˈpætʃiː is an American non profit corporation to support Apache software projects including the Apache HTTP Server The ASF was formed from the Apache Group and incorporated in Delaware U S in June 1999 The Apache Software Foundation is a decentralized open source community of developers The software they produce is distributed under the terms of the Apache License and is free and open source software The Apache projects are characterized by a collaborative consensus based development process and an open and pragmatic software license Each project is managed by a self selected team of technical experts who are active contributors to the project The ASF is a meritocracy implying that membership of the foundation is granted only to volunteers who have actively contributed to Apache projects The ASF is considered a second generation open source organization in th This channel was generated automatically by YouTube s video discovery system\t169\t0\nid:youtube:UCwhtqOdWyCuqOboj-E1bpFQ\tApache Spark - Topic\tApache Spark is an open source cluster computing framework Originally developed at the University of California Berkeley s AMPLab the Spark codebase was later donated to the Apache Software Foundation which has maintained it since Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance This channel was generated automatically by YouTube s video discovery system\t123\t0\nid:youtube:UCkrSQVb5Qzb13crS1kCOiQQ\tApache Syncope\t\t13\t5\nid:youtube:UC6nsS04n_wBpCDXqSAkFM-w\tApache Cassandra - Topic\tApache Cassandra is a free and open source distributed database management system designed to handle large amounts of data across many commodity servers providing high availability with no single point of failure Cassandra offers robust support for clusters spanning multiple datacenters with asynchronous masterless replication allowing low latency operations for all clients Cassandra also places a high value on performance In 2012 University of Toronto researchers studying NoSQL systems concluded that In terms of scalability there is a clear winner throughout our experiments Cassandra achieves the highest throughput for the maximum number of nodes in all experiments although this comes at the price of high write and read latencies This channel was generated automatically by YouTube s video discovery system\t90\t0\nid:youtube:UCcGNHRiO9bi6BeH5OdhY2Kw\tApache HBase - Topic\tHBase is an open source non relational distributed database modeled after Google s BigTable and is written in Java It is developed as part of Apache Software Foundation s Apache Hadoop project and runs on top of HDFS providing BigTable like capabilities for Hadoop That is it provides a fault tolerant way of storing large quantities of sparse data HBase features compression in memory operation and Bloom filters on a per column basis as outlined in the original BigTable paper Tables in HBase can serve as the input and output for MapReduce jobs run in Hadoop and may be accessed through the Java API but also through REST Avro or Thrift gateway APIs HBase is a column oriented key value data store and has been idolized widely because of its lineage with Hadoop and HDFS HBase runs on top of HDFS and is well suited for faster read and write operations on large datasets with high throughput and low in This channel was generated automatically by YouTube s video discovery system\t32\t0\nid:youtube:UCIjbkZAX5VlvSKoSzNUHIoQ\tApache Hive - Topic\tApache Hive is a data warehouse infrastructure built on top of Hadoop for providing data summarization query and analysis Hive gives an SQL like interface to query data stored in various databases and file systems that integrate with Hadoop The traditional SQL queries must be implemented in the MapReduce Java API to execute SQL applications and queries over a distributed data Hive provides the necessary SQL abstraction to integrate SQL like Queries into the underlying Java API without the need to implement queries in the low level Java API Since most of the data warehousing application work with SQL based querying language Hive supports easy portability of SQL based application to Hadoop While initially developed by Facebook Apache Hive is now used and developed by other companies such as Netflix and the Financial Industry Regulatory Authority Amazon maintains a software fork of Apache Hive that This channel was generated automatically by YouTube s video discovery system\t82\t0\nid:youtube:UCgRu3LbCjczooTVI9VSvstg\tApache Hadoop - Topic\tApache Hadoop is an open source software framework used for distributed storage and processing of very large data sets It consists of computer clusters built from commodity hardware All the modules in Hadoop are designed with a fundamental assumption that hardware failures are a common occurrence and should be automatically handled by the framework The core of Apache Hadoop consists of a storage part known as Hadoop Distributed File System and a processing part called MapReduce Hadoop splits files into large blocks and distributes them across nodes in a cluster It then transfers packaged code into nodes to process the data parallely This approach takes advantage of data locality – nodes manipulating the data they have access to – to allow the dataset to be processed faster and more efficiently than it would be in a more conventional supercomputer architecture that relies on a parallel file system w This channel was generated automatically by YouTube s video discovery system\t1236\t0\nid:youtube:UCzHCk8Gl5eP85xz0HwXjkzw\tApache Avro - Topic\tAvro is a remote procedure call and data serialization framework developed within Apache s Hadoop project It uses JSON for defining data types and protocols and serializes data in a compact binary format Its primary use is in Apache Hadoop where it can provide both a serialization format for persistent data and a wire format for communication between Hadoop nodes and from client programs to the Hadoop services It is similar to Thrift but does not require running a code generation program when a schema changes Apache Spark SQL can access Avro as a data source This channel was generated automatically by YouTube s video discovery system\t10\t0\nid:youtube:UCBS2s2cwx-MW9rVeKwee_VA\tApache Maven - Topic\tMaven is a build automation tool used primarily for Java projects The word maven means accumulator of knowledge in Yiddish Maven addresses two aspects of building software first it describes how software is built and second it describes its dependencies Contrary to preceding tools like Apache Ant it uses conventions for the build procedure and only exceptions need to be written down An XML file describes the software project being built its dependencies on other external modules and components the build order directories and required plug ins It comes with pre defined targets for performing certain well defined tasks such as compilation of code and its packaging Maven dynamically downloads Java libraries and Maven plug ins from one or more repositories such as the Maven 2 Central Repository and stores them in a local cache This local cache of downloaded artifacts can also be updated wit This channel was generated automatically by YouTube s video discovery system\t264\t0\nid:youtube:UCRyBrviuu3qMNliolYXvC0g\tApache Oozie - Topic\tApache Oozie is a server based workflow scheduling system to manage Hadoop jobs Workflows in Oozie are defined as a collection of control flow and action nodes in a directed acyclic graph Control flow nodes define the beginning and the end of a workflow as well as a mechanism to control the workflow execution path Action nodes are the mechanism by which a workflow triggers the execution of a computation processing task Oozie provides support for different types of actions including Hadoop MapReduce Hadoop distributed file system operations Pig SSH and email Oozie can also be extended to support additional types of actions Oozie workflows can be parameterised using variables such as ${inputDir} within the workflow definition When submitting a workflow job values for the parameters must be provided If properly parameterized several identical workflow jobs can run concurrently Oozie is implemen This channel was generated automatically by YouTube s video discovery system\t20\t0\n","comment":"","msgTable":[[{"key":"displayName","value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"key":"displayName","value":"Apache Flink Berlin"},{"key":"displayName","value":"Apache Flink is a programming environment and distributed runtime that makes it easy for developers to build batch and streaming data applications Flink offers familiar fluent programming APIs and a set of libraries and backs these APIs with a robust and hybrid execution engine that unifies stream and batch processing Flink entered the Apache Incubator in April 2014 and graduated in December 2014 Be sure to check out www flink forward org Flink Forward 2015 is the first conference to bring together the Apache Flink developer and user community"},{"key":"displayName","value":662},{"key":"displayName","value":127}],[{"key":"summary","value":"id:youtube:UCegQNPmRCAJvCq6JfHUKZ9A"},{"key":"summary","value":"Apache Software Foundation - Topic"},{"key":"summary","value":"The Apache Software Foundation əˈpætʃiː is an American non profit corporation to support Apache software projects including the Apache HTTP Server The ASF was formed from the Apache Group and incorporated in Delaware U S in June 1999 The Apache Software Foundation is a decentralized open source community of developers The software they produce is distributed under the terms of the Apache License and is free and open source software The Apache projects are characterized by a collaborative consensus based development process and an open and pragmatic software license Each project is managed by a self selected team of technical experts who are active contributors to the project The ASF is a meritocracy implying that membership of the foundation is granted only to volunteers who have actively contributed to Apache projects The ASF is considered a second generation open source organization in th This channel was generated automatically by YouTube s video discovery system"},{"key":"summary","value":169},{"key":"summary","value":0}],[{"key":"followers","value":"id:youtube:UCwhtqOdWyCuqOboj-E1bpFQ"},{"key":"followers","value":"Apache Spark - Topic"},{"key":"followers","value":"Apache Spark is an open source cluster computing framework Originally developed at the University of California Berkeley s AMPLab the Spark codebase was later donated to the Apache Software Foundation which has maintained it since Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance This channel was generated automatically by YouTube s video discovery system"},{"key":"followers","value":123},{"key":"followers","value":0}],[{"key":"posts","value":"id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ"},{"key":"posts","value":"Apache Syncope"},{"key":"posts","value":""},{"key":"posts","value":13},{"key":"posts","value":5}],[{"value":"id:youtube:UC6nsS04n_wBpCDXqSAkFM-w"},{"value":"Apache Cassandra - Topic"},{"value":"Apache Cassandra is a free and open source distributed database management system designed to handle large amounts of data across many commodity servers providing high availability with no single point of failure Cassandra offers robust support for clusters spanning multiple datacenters with asynchronous masterless replication allowing low latency operations for all clients Cassandra also places a high value on performance In 2012 University of Toronto researchers studying NoSQL systems concluded that In terms of scalability there is a clear winner throughout our experiments Cassandra achieves the highest throughput for the maximum number of nodes in all experiments although this comes at the price of high write and read latencies This channel was generated automatically by YouTube s video discovery system"},{"value":90},{"value":0}],[{"value":"id:youtube:UCcGNHRiO9bi6BeH5OdhY2Kw"},{"value":"Apache HBase - Topic"},{"value":"HBase is an open source non relational distributed database modeled after Google s BigTable and is written in Java It is developed as part of Apache Software Foundation s Apache Hadoop project and runs on top of HDFS providing BigTable like capabilities for Hadoop That is it provides a fault tolerant way of storing large quantities of sparse data HBase features compression in memory operation and Bloom filters on a per column basis as outlined in the original BigTable paper Tables in HBase can serve as the input and output for MapReduce jobs run in Hadoop and may be accessed through the Java API but also through REST Avro or Thrift gateway APIs HBase is a column oriented key value data store and has been idolized widely because of its lineage with Hadoop and HDFS HBase runs on top of HDFS and is well suited for faster read and write operations on large datasets with high throughput and low in This channel was generated automatically by YouTube s video discovery system"},{"value":32},{"value":0}],[{"value":"id:youtube:UCIjbkZAX5VlvSKoSzNUHIoQ"},{"value":"Apache Hive - Topic"},{"value":"Apache Hive is a data warehouse infrastructure built on top of Hadoop for providing data summarization query and analysis Hive gives an SQL like interface to query data stored in various databases and file systems that integrate with Hadoop The traditional SQL queries must be implemented in the MapReduce Java API to execute SQL applications and queries over a distributed data Hive provides the necessary SQL abstraction to integrate SQL like Queries into the underlying Java API without the need to implement queries in the low level Java API Since most of the data warehousing application work with SQL based querying language Hive supports easy portability of SQL based application to Hadoop While initially developed by Facebook Apache Hive is now used and developed by other companies such as Netflix and the Financial Industry Regulatory Authority Amazon maintains a software fork of Apache Hive that This channel was generated automatically by YouTube s video discovery system"},{"value":82},{"value":0}],[{"value":"id:youtube:UCgRu3LbCjczooTVI9VSvstg"},{"value":"Apache Hadoop - Topic"},{"value":"Apache Hadoop is an open source software framework used for distributed storage and processing of very large data sets It consists of computer clusters built from commodity hardware All the modules in Hadoop are designed with a fundamental assumption that hardware failures are a common occurrence and should be automatically handled by the framework The core of Apache Hadoop consists of a storage part known as Hadoop Distributed File System and a processing part called MapReduce Hadoop splits files into large blocks and distributes them across nodes in a cluster It then transfers packaged code into nodes to process the data parallely This approach takes advantage of data locality – nodes manipulating the data they have access to – to allow the dataset to be processed faster and more efficiently than it would be in a more conventional supercomputer architecture that relies on a parallel file system w This channel was generated automatically by YouTube s video discovery system"},{"value":1236},{"value":0}],[{"value":"id:youtube:UCzHCk8Gl5eP85xz0HwXjkzw"},{"value":"Apache Avro - Topic"},{"value":"Avro is a remote procedure call and data serialization framework developed within Apache s Hadoop project It uses JSON for defining data types and protocols and serializes data in a compact binary format Its primary use is in Apache Hadoop where it can provide both a serialization format for persistent data and a wire format for communication between Hadoop nodes and from client programs to the Hadoop services It is similar to Thrift but does not require running a code generation program when a schema changes Apache Spark SQL can access Avro as a data source This channel was generated automatically by YouTube s video discovery system"},{"value":10},{"value":0}],[{"value":"id:youtube:UCBS2s2cwx-MW9rVeKwee_VA"},{"value":"Apache Maven - Topic"},{"value":"Maven is a build automation tool used primarily for Java projects The word maven means accumulator of knowledge in Yiddish Maven addresses two aspects of building software first it describes how software is built and second it describes its dependencies Contrary to preceding tools like Apache Ant it uses conventions for the build procedure and only exceptions need to be written down An XML file describes the software project being built its dependencies on other external modules and components the build order directories and required plug ins It comes with pre defined targets for performing certain well defined tasks such as compilation of code and its packaging Maven dynamically downloads Java libraries and Maven plug ins from one or more repositories such as the Maven 2 Central Repository and stores them in a local cache This local cache of downloaded artifacts can also be updated wit This channel was generated automatically by YouTube s video discovery system"},{"value":264},{"value":0}],[{"value":"id:youtube:UCRyBrviuu3qMNliolYXvC0g"},{"value":"Apache Oozie - Topic"},{"value":"Apache Oozie is a server based workflow scheduling system to manage Hadoop jobs Workflows in Oozie are defined as a collection of control flow and action nodes in a directed acyclic graph Control flow nodes define the beginning and the end of a workflow as well as a mechanism to control the workflow execution path Action nodes are the mechanism by which a workflow triggers the execution of a computation processing task Oozie provides support for different types of actions including Hadoop MapReduce Hadoop distributed file system operations Pig SSH and email Oozie can also be extended to support additional types of actions Oozie workflows can be parameterised using variables such as ${inputDir} within the workflow definition When submitting a workflow job values for the parameters must be provided If properly parameterized several identical workflow jobs can run concurrently Oozie is implemen This channel was generated automatically by YouTube s video discovery system"},{"value":20},{"value":0}]],"columnNames":[{"name":"id","index":0,"aggr":"sum"},{"name":"displayName","index":1,"aggr":"sum"},{"name":"summary","index":2,"aggr":"sum"},{"name":"followers","index":3,"aggr":"sum"},{"name":"posts","index":4,"aggr":"sum"}],"rows":[["id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink is a programming environment and distributed runtime that makes it easy for developers to build batch and streaming data applications Flink offers familiar fluent programming APIs and a set of libraries and backs these APIs with a robust and hybrid execution engine that unifies stream and batch processing Flink entered the Apache Incubator in April 2014 and graduated in December 2014 Be sure to check out www flink forward org Flink Forward 2015 is the first conference to bring together the Apache Flink developer and user community",662,127],["id:youtube:UCegQNPmRCAJvCq6JfHUKZ9A","Apache Software Foundation - Topic","The Apache Software Foundation əˈpætʃiː is an American non profit corporation to support Apache software projects including the Apache HTTP Server The ASF was formed from the Apache Group and incorporated in Delaware U S in June 1999 The Apache Software Foundation is a decentralized open source community of developers The software they produce is distributed under the terms of the Apache License and is free and open source software The Apache projects are characterized by a collaborative consensus based development process and an open and pragmatic software license Each project is managed by a self selected team of technical experts who are active contributors to the project The ASF is a meritocracy implying that membership of the foundation is granted only to volunteers who have actively contributed to Apache projects The ASF is considered a second generation open source organization in th This channel was generated automatically by YouTube s video discovery system",169,0],["id:youtube:UCwhtqOdWyCuqOboj-E1bpFQ","Apache Spark - Topic","Apache Spark is an open source cluster computing framework Originally developed at the University of California Berkeley s AMPLab the Spark codebase was later donated to the Apache Software Foundation which has maintained it since Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance This channel was generated automatically by YouTube s video discovery system",123,0],["id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ","Apache Syncope","",13,5],["id:youtube:UC6nsS04n_wBpCDXqSAkFM-w","Apache Cassandra - Topic","Apache Cassandra is a free and open source distributed database management system designed to handle large amounts of data across many commodity servers providing high availability with no single point of failure Cassandra offers robust support for clusters spanning multiple datacenters with asynchronous masterless replication allowing low latency operations for all clients Cassandra also places a high value on performance In 2012 University of Toronto researchers studying NoSQL systems concluded that In terms of scalability there is a clear winner throughout our experiments Cassandra achieves the highest throughput for the maximum number of nodes in all experiments although this comes at the price of high write and read latencies This channel was generated automatically by YouTube s video discovery system",90,0],["id:youtube:UCcGNHRiO9bi6BeH5OdhY2Kw","Apache HBase - Topic","HBase is an open source non relational distributed database modeled after Google s BigTable and is written in Java It is developed as part of Apache Software Foundation s Apache Hadoop project and runs on top of HDFS providing BigTable like capabilities for Hadoop That is it provides a fault tolerant way of storing large quantities of sparse data HBase features compression in memory operation and Bloom filters on a per column basis as outlined in the original BigTable paper Tables in HBase can serve as the input and output for MapReduce jobs run in Hadoop and may be accessed through the Java API but also through REST Avro or Thrift gateway APIs HBase is a column oriented key value data store and has been idolized widely because of its lineage with Hadoop and HDFS HBase runs on top of HDFS and is well suited for faster read and write operations on large datasets with high throughput and low in This channel was generated automatically by YouTube s video discovery system",32,0],["id:youtube:UCIjbkZAX5VlvSKoSzNUHIoQ","Apache Hive - Topic","Apache Hive is a data warehouse infrastructure built on top of Hadoop for providing data summarization query and analysis Hive gives an SQL like interface to query data stored in various databases and file systems that integrate with Hadoop The traditional SQL queries must be implemented in the MapReduce Java API to execute SQL applications and queries over a distributed data Hive provides the necessary SQL abstraction to integrate SQL like Queries into the underlying Java API without the need to implement queries in the low level Java API Since most of the data warehousing application work with SQL based querying language Hive supports easy portability of SQL based application to Hadoop While initially developed by Facebook Apache Hive is now used and developed by other companies such as Netflix and the Financial Industry Regulatory Authority Amazon maintains a software fork of Apache Hive that This channel was generated automatically by YouTube s video discovery system",82,0],["id:youtube:UCgRu3LbCjczooTVI9VSvstg","Apache Hadoop - Topic","Apache Hadoop is an open source software framework used for distributed storage and processing of very large data sets It consists of computer clusters built from commodity hardware All the modules in Hadoop are designed with a fundamental assumption that hardware failures are a common occurrence and should be automatically handled by the framework The core of Apache Hadoop consists of a storage part known as Hadoop Distributed File System and a processing part called MapReduce Hadoop splits files into large blocks and distributes them across nodes in a cluster It then transfers packaged code into nodes to process the data parallely This approach takes advantage of data locality – nodes manipulating the data they have access to – to allow the dataset to be processed faster and more efficiently than it would be in a more conventional supercomputer architecture that relies on a parallel file system w This channel was generated automatically by YouTube s video discovery system",1236,0],["id:youtube:UCzHCk8Gl5eP85xz0HwXjkzw","Apache Avro - Topic","Avro is a remote procedure call and data serialization framework developed within Apache s Hadoop project It uses JSON for defining data types and protocols and serializes data in a compact binary format Its primary use is in Apache Hadoop where it can provide both a serialization format for persistent data and a wire format for communication between Hadoop nodes and from client programs to the Hadoop services It is similar to Thrift but does not require running a code generation program when a schema changes Apache Spark SQL can access Avro as a data source This channel was generated automatically by YouTube s video discovery system",10,0],["id:youtube:UCBS2s2cwx-MW9rVeKwee_VA","Apache Maven - Topic","Maven is a build automation tool used primarily for Java projects The word maven means accumulator of knowledge in Yiddish Maven addresses two aspects of building software first it describes how software is built and second it describes its dependencies Contrary to preceding tools like Apache Ant it uses conventions for the build procedure and only exceptions need to be written down An XML file describes the software project being built its dependencies on other external modules and components the build order directories and required plug ins It comes with pre defined targets for performing certain well defined tasks such as compilation of code and its packaging Maven dynamically downloads Java libraries and Maven plug ins from one or more repositories such as the Maven 2 Central Repository and stores them in a local cache This local cache of downloaded artifacts can also be updated wit This channel was generated automatically by YouTube s video discovery system",264,0],["id:youtube:UCRyBrviuu3qMNliolYXvC0g","Apache Oozie - Topic","Apache Oozie is a server based workflow scheduling system to manage Hadoop jobs Workflows in Oozie are defined as a collection of control flow and action nodes in a directed acyclic graph Control flow nodes define the beginning and the end of a workflow as well as a mechanism to control the workflow execution path Action nodes are the mechanism by which a workflow triggers the execution of a computation processing task Oozie provides support for different types of actions including Hadoop MapReduce Hadoop distributed file system operations Pig SSH and email Oozie can also be extended to support additional types of actions Oozie workflows can be parameterised using variables such as ${inputDir} within the workflow definition When submitting a workflow job values for the parameters must be provided If properly parameterized several identical workflow jobs can run concurrently Oozie is implemen This channel was generated automatically by YouTube s video discovery system",20,0]]},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-18T23:59:40-0600","dateFinished":"2016-11-18T23:59:40-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:260"},{"title":"","text":"%spark.sql\nselect id, published, actor.id, actor.displayName, content, title from youtube_posts\n","user":"anonymous","dateUpdated":"2016-11-18T23:59:40-0600","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","optionOpen":false,"keys":[{"name":"id","index":0,"aggr":"sum"}],"values":[],"scatter":{"xAxis":{"name":"id","index":0,"aggr":"sum"}},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141066_-630916770","id":"20161114-115056_161108156","result":{"code":"SUCCESS","type":"TABLE","msg":"id\tpublished\tid\tdisplayName\tcontent\ttitle\nid:youtube:post:RYoFwQFvC_g\t2016-11-17T14:29:43.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tTwo days of conference One day of training More than 350 attendees from all over the globe over 40 international speakers 3 stages and lots of squirrels – At Flink Forward Berlin we’ve enjoyed three days full of exciting training sessions keynotes technical talks and panels It was the second Flink Forward organized by data Artisans and we want to thank you for trusting us and making next year’s conferences in San Francisco and Berlin a blast droidcon Berlin – http droidcon de Facebook https www facebook com dr Google+ https plus google com +dr Twitter https twitter com droidconDE Instagram https instagram com droid LinkedIn https www linkedin com gr XING https www xing com commun Find more information on all droidcons worldwide on http droidcon com\tA taste of Flink Forward\nid:youtube:post:inFPmLV6FPI\t2016-09-27T15:38:10.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tJamie Grier Director of Applications Engineering at data Artisans talks about his work at data Artisans and the Apache Flink projects he is involved with\tInterview with Jamie Grier, Director of Applications Engineering at data Artisans\nid:youtube:post:TI-uQtB57D4\t2016-09-27T15:31:11.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tMárton Balassi Solutions Architect at Cloudera talks about his work and the Apache Flink community\tInterview with Márton Balassi, Solutions Architect at Cloudera\nid:youtube:post:LvFcTedwpiI\t2016-09-27T15:23:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tGyula Fóra Data Warehouse Engineer at King talks about his work and the most exciting Flink features to come\tInterview with Gyula Fóra, Data Warehouse Engineer at King\nid:youtube:post:6uvrWMbZ6xQ\t2016-03-23T09:40:41.000Z\tid:youtube:UCkrSQVb5Qzb13crS1kCOiQQ\tApache Syncope\thttp syncope tirasa net news apache syncope 2 0 0 dashboard html\tApache Syncope 2.0.0 Dashboard\nid:youtube:post:-VMoF70hwSA\t2016-09-27T15:19:36.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tTed Dunning Chief Application Architect at MapR Technologies talks about his work and his first involvement in Apache Flink\tInterview with Ted Dunning, Chief Application Architect at MapR Technologies\nid:youtube:post:ARJLp6xhKo8\t2016-09-27T15:11:45.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tMaxim Fateev staff engineer at Uber talks about his projects at Uber and his experiences with Apache Flink\tInterview with Maxim Fateev, staff engineer at Uber\nid:youtube:post:xxKzjV2vmSA\t2015-10-12T15:14:02.000Z\tid:youtube:UCkrSQVb5Qzb13crS1kCOiQQ\tApache Syncope\thttp syncope tirasa net news apache syncope 2 0 0 and swagger html\tApache Syncope 2.0.0 and Swagger UI\nid:youtube:post:vl7Q2lKyPn8\t2015-08-13T10:48:25.000Z\tid:youtube:UCkrSQVb5Qzb13crS1kCOiQQ\tApache Syncope\thttp syncope tirasa net news apache syncope 2 0 resource management html\tApache Syncope console 2.0 - Work in progress\nid:youtube:post:EAFsq7QwFAc\t2016-09-26T12:50:50.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tAljoscha Krettek stepped in for Robert Metzger http flink forward org kb_sessions connecting apache flink with the world reviewing the streaming connectors Getting data in and out of Flink in a reliable fashion is one of the most important tasks of a stream processor This talk will review the most important and frequently used connectors in Flink Apache Kafka and Amazon Kinesis Streams both fall into the same category of distributed high throughput and durable publish subscribe messaging systems The talk will explain how the connectors in Flink for these systems are implemented In particular we’ll focus on how we ensure exactly once semantics while consuming data and how offsets sequence numbers are handled We will also review two generic tools in Flink for connectors A message acknowledging source for classical message queues like those implementing AMQP and a generic write ahead log sink using Flink’s state backend abstraction The objective of the talk is to explain the internals of the streaming connectors so that people can understand their behavior configure them properly and implement their own connectors\tFlink Forward 2016: Aljoscha Krettek - Connecting Apache Flink to the World...\nid:youtube:post:2MWn7DlCfjY\t2014-05-28T13:03:36.000Z\tid:youtube:UCkrSQVb5Qzb13crS1kCOiQQ\tApache Syncope\t\tSyncope Compliance Dashboard - Connectors Status\nid:youtube:post:e-9Z_213_ZU\t2016-09-26T12:37:24.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions to petascale and beyond apache flink in the clouds Apache Flink performs with low latency but can also scale to great heights Gelly is Flink s laboratory for building and tuning scalable graph algorithms and analytics In this talk we ll discuss writing algorithms optimized for the Flink architecture assembling and configuring a cloud compute cluster and boosting performance through benchmarking and system profiling This talk will cover recent developments in the Gelly library to include scalable graph generators and a mixed collection of modular algorithms written with native Flink operators We ll think like a data stream keep a cool cache and send the garbage collector on holiday To this we ll add a lightweight benchmarking harness to stress and validate core Flink and to identify and refactor hot code with aplomb\tFlink Forward 2016: Greg Hogan -To Petascale and Beyond: Apache Flink in the Clouds\nid:youtube:post:ahgu59FqhrM\t2014-05-28T12:58:32.000Z\tid:youtube:UCkrSQVb5Qzb13crS1kCOiQQ\tApache Syncope\t\tSyncope Compliance Dashboard - Architecture Overview\nid:youtube:post:L21N8mNtvME\t2016-09-26T12:32:07.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions multi tenant flink as a service on yarn Since June 2016 Flink as a service has been available to researchers and companies in Sweden from the Swedish ICT SICS Data Center at www hops site using the HopsWorks platform Flink applications can be either deployed as jobs batch or streaming or written and run directly from Apache Zeppelin on YARN Flink applications are run within a project on a YARN cluster with the novel property that Flink applications are metered and charged to projects Projects are also securely isolated from each other and include support for project specific Kafka topics that are protected from access by users that are not members of the project Hopsworks is entirely UI driven is open source and Flink applications that include Kafka topics can be created in a few mouse clicks In this talk we will discuss the challenges in building a metered version of Flink as a Service for YARN experiences with Flink on YARN and some of the possibilities that Hopsworks opens up for building secure multi ten\tFlink Forward 2016: Jim Dowling - Multi-tenant Flink-as-a-Service on YARN\nid:youtube:post:uscx9MrSKWY\t2016-09-26T12:17:12.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions code generation in serializers and comparators of apache flink Performance of Big Data applications are often limited by serializers and comparators In the case of Flink despite its delicate type system hand writing serializers leads to a 10 improvement for a simple WordCount job using Pojos There are applications where the gain can be even more about 30 A significant amount of the overhead is the result of using reflection to access the fields of Pojo objects There is some additional overhead due to the fact that the JVM has a hard time to optimize the current default serializers and comparators because of their dynamic nature In order to improve the performance I implemented runtime code generation to generate specialized code for each Pojo type at runtime to improve the performance The generated code accesses fields without reflection and easier to optimize In the talk I will give a detailed overview of the challenges of implementing code generation the solutions and some measurements about the performance improvements\tFlink Forward 2016: Gábor Horváth - Code Generation in Serializers and Comparators of Apache Flink\nid:youtube:post:BZJnNfSBdQ8\t2016-09-26T12:11:01.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions flink security enhancements Recent security enhancements to Flink make it easy to access secure data and to protect the associated credentials In this talk we’ll describe and demonstrate the new features including Kerberos based access to HDFS and Kafka transport security TLS and service level authorization which protects your Flink cluster from unauthorized access\tFlink Forward 2016: Eron Wright -  Flink Security Enhancements\nid:youtube:post:nXQvBy_onfs\t2016-09-26T12:10:47.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions introducing flink on mesos Apache Flink supports a variety of deployment modes with support for Apache Mesos new to Flink 1 2 This talk will cover the benefits and major features of Flink on Mesos We’ll demonstrate the functionality and discuss future directions\tFlink Forward 2016: Eron Wright - Introducing Flink on Mesos\nid:youtube:post:TKcnMA7fn-s\t2016-09-26T12:08:01.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions taking a look under the hood of apache flinks relational apis Apache Flink features two APIs which are based on relational algebra a SQL interface and the so called Table API which is a LINQ style API available for Scala and Java Relational APIs are interesting because they are easy to use and queries can be automatically optimized and translated into efficient runtime code Flink offers both APIs for streaming and batch data sources This talk will take a look under the hood of Flink’s relational APIs We will show the unified architecture to handle streaming and batch queries and explain how Flink translates queries of both APIs into the same representation leverages Apache Calcite to optimize them and generates runtime code for efficient execution Finally we will discuss potential improvements and give an outlook for future extensions and features\tFlink Forward 2016: Fabian Hueske - Taking a look under the hood of Apache Flink’s relational APIs\nid:youtube:post:vws5bv3XdD8\t2016-09-26T12:06:31.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions declarative stream processing with streamsql and cep Complex event processing CEP and stream analytics are commonly treated as distinct classes of stream processing applications While CEP workloads identify patterns from event streams in near real time stream analytics queries ingest and aggregate high volume streams Both types of use cases have very different requirements which resulted in diverging system designs CEP systems excel at low latency processing whereas engines for stream analytics achieve high throughput Recent advances in open source stream processing yielded systems that can process several millions of events per second at sub second latency Systems like Apache Flink enable applications that include typical CEP features as well as heavy aggregations In this talk we will show how Apache Flink unifies CEP and stream analytics workloads Guided by examples we introduce Flink’s CEP enriched StreamSQL interface and discuss how queries are compiled optimized and executed on Flink\tFlink Forward 2016: Fabian Hueske & Till Rohrmann - Declarative stream processing...\nid:youtube:post:uuv-lnOrD0o\t2016-09-26T11:06:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions the stream processor as a database building online applications directly on streams We present a new design pattern for data streaming applications using Apache Flink and Apache Kafka Building applications directly on top of the stream processor rather than on top of key value databases populated by data streams Unlike classical setups that use stream processors or libraries to pre process aggregate events and update a database with the results this setup simply gives the role of the database to the stream processor here Apache Flink routing queries to its workers who directly answer them from their internal state computed over the log of events Apache Kafka This talk will cover both the high level introduction to the architecture the techniques in Flink Kafka that make this approach possible as well as experiences from a large scale setup and technical details\tFlink Forward 2016: Jamie Grier - The Stream Processor as a Database\nid:youtube:post:3ySKJN5bbjk\t2016-09-26T10:45:41.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions dynamic scaling how apache flink adapts to changing workloads Modern stream processing engines not only have to process millions of events per second at sub second latency but also have to cope with constantly changing workloads Due to the dynamic nature of stream applications where the number of incoming events can strongly vary with time systems cannot reliably predetermine the amount of required resources In order to meet guaranteed SLAs as well as utilizing system resources as efficiently as possible frameworks like Apache Flink have to adapt their resource consumption dynamically In this talk we will take a look under the hood and explain how Flink scales stateful application in and out Starting with the concept of key groups and partionable state we will cover ways to detect bottlenecks in streaming jobs and discuss efficient strategies how to scale out operators with minimal down time\tFlink Forward 2016: Till Rohrmann - Dynamic Scaling - How Apache Flink adapts to changing workloads\nid:youtube:post:17tUR4TsvpM\t2016-09-26T10:33:49.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions rbea scalable real time analytics at king This talk introduces RBEA Rule Based Event Aggregator the scalable real time analytics platform developed by King’s Streaming Platform team We have built RBEA to make real time analytics easily accessible to game teams across King without having to worry about operational details RBEA is built on top of Apache Flink and uses the framework s capabilities to it s full potential in order to provide highly scalable stateful and windowed processing logic for the analytics applications We will talk about how we have built a high level DSL on the abstractions provided by Flink and how we tackled different technical challenges that have come up while developing the system\tFlink Forward 2016: Gyula Fóra - RBEA- Scalable Real-Time Analytics at King\nid:youtube:post:udQcdwa8jbg\t2016-09-26T10:22:08.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions flink in zalandos world of microservices In this talk we present Zalando s microservices architecture introduce Saiki – our next generation data integration and distribution platform on AWS and show how we employ stream processing with Apache Flink for near real time business intelligence Zalando is one of the largest online fashion retailers in Europe In order to secure our future growth and remain competitive in this dynamic market we are transitioning from a monolithic to a microservices architecture and from a hierarchical to an agile organization We first have a look at how business intelligence processes have been working inside Zalando for the last years and present our current approach Saiki It is a scalable cloud based data integration and distribution infrastructure that makes data from our many microservices readily available for analytical teams We no longer live in a world of static data sets but are instead confronted with endless streams of events that constantly inform us about relevant happenings from all over the enterprise The processing of these event streams enables us to do near real time business intelligence In this context we have evaluated Apache Flink vs Apache Spark in order to choose the right stream processing framework Given our requirements we decided to use Flink as part of our technology stack alongside with Kafka and Elasticsearch With these technologies we are currently working on two use cases a near real time business process monitoring solution and streaming ETL Monitoring our business processes enables us to check if technically the Zalando platform works It also helps us analyze data streams on the fly e g order velocities delivery velocities and to control service level agreements On the other hand streaming ETL is used to relinquish resources from our relational data warehouse as it struggles with increasingly high loads In addition to that it also reduces the latency and facilitates the platform scalability Finally we have an outlook on our future use cases e g near real time sales and price monitoring Another aspect to be addressed is to lower the entry barrier of stream processing for our colleagues coming from a relational database background\tFlink Forward 2016: Javier Lopez & Mihail Vieru - Flink in Zalando's World of Microservices\nid:youtube:post:X83rmmb6rgs\t2016-09-26T10:06:56.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions apache beam a unified model for batch and streaming data processing Unbounded unordered global scale datasets are increasingly common in day to day business and consumers of these datasets have detailed requirements for latency cost and completeness Apache Beam incubating defines a new data processing programming model that evolved from more than a decade of experience within Google including MapReduce FlumeJava MillWheel and Cloud Dataflow Beam handles both batch and streaming use cases and neatly separates properties of the data from runtime characteristics allowing pipelines to be portable across multiple runtimes both open source e g Apache Flink Apache Spark et al and proprietary e g Google Cloud Dataflow This talk will cover the basics of Apache Beam touch on its evolution describe main concepts in the programming model and compare with similar systems We’ll go from a simple scenario to a relatively complex data processing pipeline and finally demonstrate execution of that pipeline on multiple runtimes\tFlink Forward 2016: Kenneth Knowles -  Apache Beam: A Unified Model for...\nid:youtube:post:msdjh6KRXC8\t2016-09-26T09:50:21.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions flink and beam current state roadmap It is no secret that the Dataflow model which evolved from Google’s MapReduce Flume and MillWheel has been a major influence to Apache Flink’s streaming API The essentials of this model are captured in Apache Beam Beam provides the Dataflow API with the option to deploy to various backends e g Flink Spark In this talk we will examine the current state of the Flink Runner Beam’s Runners manage the translation of the Beam API into the backend API The Beam project itself has made an effort to summarize the capabilities of each Runner to provide an overview of the supported API concepts From all open sources backends Flink is currently the Runner which supports the most features We will look at the supported Beam features and their counterpart in Flink Further we will look at potential improvements and upcoming features of the Flink Runner\tFlink Forward 2016: Maximilian Michels - Flink and Beam: Current State & Roadmap\nid:youtube:post:q9MPTCpWmuM\t2016-09-26T09:27:08.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions no shard left behind dynamic work rebalancing in apache beam The Apache Beam incubating programming model is designed to support several advanced data processing features such as autoscaling and dynamic work rebalancing In this talk we will first explain how dynamic work rebalancing not only provides a general and robust solution to the problem of stragglers in traditional data processing pipelines but also how it allows autoscaling to be truly effective We will then present how dynamic work rebalancing works as implemented in Google Cloud Dataflow and which path other Apache Beam runners link Apache Flink can follow to benefit from it\tFlink Forward 2016: Malo Denielou – No shard left behind: Dynamic work rebalancing in Apache Beam\nid:youtube:post:YsWwox7Lnco\t2016-09-26T09:07:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions flink in genomics efficient and scalable processing of raw illumina bcl data A single run in genome sequencing can easily produce several terabytes of data which subsequently feed a complex pipeline of tools Typically the first step in this workflow is a rearrangement of data roughly equivalent to a matrix transposition to reconstruct the original DNA fragments from the raw BCL data where the fragments are sliced and scattered over multiple files This step is followed by the sorting of the fragments by a specific identifying tag sequence which is attached during the preparation of the sample In this talk we will present a parallel program which performs these essential operations Our BCL converter is shown to have comparable performance to the shared memory Illumina bcl2fastq tool while also enabling easy and scalable distributed memory parallelization We will describe the techniques we have used to achieve high performance and discuss the features of Flink which we have particularly appreciated as well as the ones which we think are still missing\tFlink Forward 2016 - Francesco Versaci - Flink in genomics...\nid:youtube:post:OeHSPPWLeYQ\t2016-09-26T08:41:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions building a real time tweet map with flink in six weeks It is often necessary to build a proof of concept for a bigdata project to show the feasibility to customers With OSTMap Open Source Tweet Map we proved that it is possible to accomplish this with the right choice of technologies in a short time frame OSTMap enables the user to view live geotagged tweets of the last hours on a map search all collected tweets by a term or user name and view the amount of incoming tweets per minute distinguished by language as a graph With OSTMap we cover several important areas of a typical big data PoC project scalability stream processing and ingest of incoming data batch processing of stored data performant queries on the data and visualization of the data To achieve this we use Apache Flink and Apache Accumulo as backend technologies AngularJS and Leaflet for the frontend OSTMap was developed iteratively using the walking skeleton approach which allowed us to increase the feature set constantly even with a strict deadline\tFlink Forward 2016 - Matthias Kricke, Martin Grimmer, Michael Schmeißer – Building a real time...\nid:youtube:post:k5pvgZUbIZA\t2016-09-26T08:27:49.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions advanced visualization of flink and spark jobs Understanding the physical plan of a big data application is often crucial for tracking down bottlenecks and faulty behavior Flink and Spark although offering useful Web UI components for monitoring and understanding the logical plan of the jobs both lack a tool that helps to understand the physical plan of the scheduler and the possibility to monitor execution at a very low level along with the communication that occur between parallel vertex instances We propose a tool that allows users to real time monitor and later to replay examine job executions on any cluster currently supported by Flink or Spark The tool also offers monitoring of the distribution of keys in a data stream and can lead to optimizing data partitioning across parallel subtasks in the future\tFlink Forward 2016: Zoltán Zvara - Advanced visualization of Flink and Spark jobs\nid:youtube:post:-iWEnSJ_zaQ\t2016-09-25T16:23:12.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions faster and furiouser flink drift Not long ago we had the opportunity to test Apache Flink to see just how fast it would go on a moderately realistic task with fast hardware and with a good streaming transport layer underneath Our goal was not so much careful comparison with other software but flat out speed Flink against Flink In the process we learned a lot about what it takes to go fast Some of the lessons were ones that we had “learned” a number of times before – the bottleneck isn’t where you thought it was – copying data is expensive – context switches are expensive – measure twice cut once But there were some real surprises along the way The really important knobs weren’t quite what people say you should turn One of the biggest surprises was the degree to which high performance libraries have threading built into them which makes the actual concurrrency much higher than the apparent concurrency The result was that at least one cluster parameter needed to be adjusted by 30x to get real\tFlink Forward 2016: Ted Dunning - Faster and Furiouser: Flink Drift\nid:youtube:post:oVDSi30U7rw\t2016-09-25T14:19:25.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions apache zeppelin a friendlier way to flink In this talk we present Apache Zeppelin notebook based web UI for working with several big data platforms including Flink In this talk we will show how to leverage several of Zeppelin’s exciting features using Flink The talk demo will be a series of examples of increasing complexity Starting with the obligatory word count example we will move on to loading additional jars to perform machine learning tasks using FlinkML we will do some examples of graph processing in Gelly and visualizing those graphs using AngularJS and d3js both native to Zeppelin give examples of how Zeppelin’s “ResourcePools” can be used to share variables between interpreters leading in to a Flink Streaming Example where variables a “bound” and visualizations update in real time pre supposes working stable Flink Streaming in REPL editors feel free to delete this comment once that has been achieved\tFlink Forward 2016: Trevor Grant -  Apache Zeppelin: A friendlier way to Flink\nid:youtube:post:FtzXOLhZ-2c\t2016-09-25T11:52:36.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions streaming ml with flink As continuous big data processing is gaining popularity it naturally implies that there is a need to transition many of the distributed machine learning functionality to a streaming backend The most common use case is to give streaming predictions based on the model learnt in batch however in some cases it is beneficial to also update the model on the fly It is not uncommon that streaming learners need different algorithms than their batch counterparts The talk discusses the common use cases and the pitfalls of the streaming ML transition through the example of recommender systems It also offer a dive into the implementation of a Scala library augmenting FlinkML with streaming predictors\tFlink Forward 2016: Márton Balassi - Streaming ML with Flink\nid:youtube:post:k8RIjuwqIds\t2016-09-25T09:36:51.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions streaming sql Streaming is necessary to handle data rates and latency but SQL is unquestionably the lingua franca of data Is it possible to combine SQL with streaming and if so what does the resulting language look like Apache Calcite is extending SQL to include streaming and Apache Flink is using Calcite to support both regular and streaming SQL In this talk Julian Hyde describes streaming SQL in detail and shows how you can use streaming SQL in your application He also describes how Calcite’s planner optimizes queries for throughput and latency\tFlink Forward 2016: Julian Hyde - Streaming SQL\nid:youtube:post:rbvTVQNY8UQ\t2016-09-25T07:46:47.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions panel large scale streaming in production As stream processing systems become more mainstream companies are looking to empower their users to take advantage of this technology Stream processing systems promise to allow users to gain valuable data insights in realtime and to simplify and improve common data processing and analytics tasks The scale of stream processing systems can be measured along several dimensions We will focus on two of them in this session The first dimension is data velocity Millions of messages per second is common for some workloads The second dimension is user base Those implementing stream processing systems need to support large and diverse user populations In this session we will have leading experts in the field talk about the challenges they have faced and the solutions they have discovered while implementing stream processing systems at very large scales We will cover the motivations behind these systems discuss the various user groups they serve and discuss the major challenges that need to be addressed Panelists Maxim Fateev Xiaowei Jiang Monal Daxini Ted Dunning Moderated by Jamie Grier\tFlink Forward: Panel: Large Scale Streaming in Production\nid:youtube:post:n679Xa3ZrFo\t2016-09-24T17:00:15.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions keynote tba Apache Flink has come a long way from its academic beginnings It is now one of the most technically advanced solutions for streaming computation And batch computation too Flink has serious technical advantages when compared with nearly every alternative system This success ironically means that Apache Flink is right on the cusp of a critical moment Over the next few months it will be decided whether Flink is the Next Big Thing or if it is a fine technology with limited impact Right now what you and I do can make a huge difference But as business people like to say what got Flink here isn’t what’s going to get it there The challenges the Flink community faces now are different from the technical challenges it has met so far I will talk about what I think will help and how we can all pitch in to take Flink forward\tFlink Forward 2016: Ted Dunning - Keynote: How Can We Take Flink Forward?\nid:youtube:post:NI1yN5FbxUM\t2016-09-24T12:09:21.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions keynote tba 2 The past 12 months saw the data streaming ecosystem mature and grow tremendously with new open source projects and products being offered in the market and more large scale production applications of streaming data It is now understood that streaming data is not a fad but a growing industry that is here to stay Apache Flink was one of the pioneering communities advocating that stream processing is a great fit for the continuous nature of data production and that batch processing can be seen and efficiently performed as a special case of stream processing Flink saw tremendous growth since the last Flink Forward conference with the project boasting now more than 200 contributors from several companies several production installations and broad adoption In this talk we discuss several large scale stream processing use cases that we see at data Artisans Additionally we discuss what this accelerated growth means for Flink how we can sustain this growth moving forward as well as a vision for the next big directions in Flink\tFlink Forward 2016: Kostas Tzoumas & Stephan Ewen - Keynote\nid:youtube:post:Jexh_GsSWWs\t2016-09-20T11:14:10.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\t\tKostas Tzoumas - Closing Session\nid:youtube:post:B2b5qMHA2GI\t2016-09-20T11:10:32.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions flinkspector taming the squirrel The costs of logic errors in production for streaming applications are higher than for batch processing systems Depending on the setup errors cannot be rectified or have already influenced important decisions The goal of Flinkspector is to improve the test process of Apache Flink streaming applications in order to detect streaming application logic errors early during development It features dedicated mechanics for test setup execution and evaluation While Flinkspector s streamlined API keeps testing overhead small The framework is able to handle non terminating and parallelized data flows involving windowing The lightweight integration tests enabled by Flinkspector allow Flink applications to be included into the continuous integration and deployment process The talk introduces the core functionality of Flinkspector In addition background concepts of the runtime and the evaluation algorithms are presented https github com ottogroup flink spector\tFlink Forward 2016: Alexander Kolb - Flinkspector: Taming the squirrel\nid:youtube:post:zlU1h0SV4SQ\t2016-09-20T10:52:47.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions large scale social network data collection and analysis with apache flink and apache streams Apache Flink offers unparalleled powered and control for streaming applications at scale wrapped in developer friendly Java and Scala SDKs simple to scale up and monitor even for high throughput applications It’s a beast an adorable beast hungry for data and we must feed it Apache Streams incubating unifies a diverse world of digital profiles and online activities into common formats and vocabularies and makes these datasets accessible through standard interfaces hiding the complexity of the underlying APIs and making the data they generate inter compatible by default Streams is the perfect tool to ingest interesting datasets to feed Flink and embedding Streams components within Flink pipelines is dead simple and downright pleasant People Pattern uses Flink and Streams to grow and maintain our database of profiles 200M and growing plus posts and connections from 10+ social networking services including Twitter Instagram Google+ Come learn how we do it\tFlink Forward 2016: Steve Blackmon - Large Scale Social Network Data Collection & Analysis...\nid:youtube:post:uXMmOjFBa94\t2016-09-20T10:38:51.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions evaluating streaming framework performance for a large scale aggregation pipeline In this talk I present the results of a set of experiments comparing the performance of several implementations of aggregating time series data There are 3 implementations a baseline implementation not using any streaming frameworks an implementation using Apache Flink and an implementation using Apache Spark Streaming These implementations all ran against the same Kafka cluster using the same data stream with the goal to understand the limitations of the different implementations The limitations were measured at 3 input data rates 100 6000 and breaking point load\tFlink Forward 2016: Ron Crocker - Evaluating Streaming Framework Performance for a Large-Scale...\nid:youtube:post:9mjAPBNl4YM\t2016-09-20T10:26:57.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions beyond the watermark on demand backfilling in flink Flink has consistency guarantees and efficient checkpointing model which make it a good fit for Uber’s money related use cases such as driver incentives However Flink’s time progress model is built around a single watermark which is incompatible with Uber’s business need for generating aggregates retroactively The talk covers our solution for on demand backfilling It also outlines other abstractions and features we expect Flink to support as it matures\tFlink Forward 2016: Maxim Fateev - Beyond the Watermark: On-Demand Backfilling in Flink\nid:youtube:post:RvgXt-PIGyI\t2016-09-20T10:10:29.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions amidst toolbox scalable probabilistic machine learning with flink In this session we would like to present our AMIDST toolbox for analysis of large scale data sets using probabilistic machine learning models AMIDST runs algorithms in a distributed fashion for learning and inference in a wide spectrum of latent variable models such as Gaussian mixtures probabilistic principal component analysis Hidden Markov Models Kalman Filters Latent Dirichlet Allocation etc This toolbox is able to perform Bayesian parameter learning on any user defined probabilistic graphical model with billions of nodes using novel distributed message passing algorithms We plan to give an overview of the AMIDST toolbox Java open source some details about the API and the integration with Flink and an analysis of the scalability of our learning algorithms All this in the context of a real use case scenario in the financial domain BCC group where the profile of millions of customers is analyzed using Flink and the Amazon Web Services\tFlink Forward 2016: Ana M. Martinez - AMIDST Toolbox: Scalable probabil. machine learning w/ Flink\nid:youtube:post:izYsMQWeUbE\t2016-09-20T10:00:35.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions a brief history of time with apache flink real time monitoring and analysis with flink kafka hb Many use cases in the telecommunication industry require producing counters quality metrics and alarms in a streaming fashion with very low latency Most of this metrics are only valuable when they’re made available as soon as the associated events happened In our company we are looking for a system able to produce this kind of real time indicator which must handle massive amounts of data 400 000 eps with often peak loads like New Year’s Eve or out of order events like massive network disorder Low latency and flexible window management with specific watermark emission are also a must haves Heterogeneous format multiple flow correlation and the possibility of late data arrival are other challenges Flink being already widely used at Bouygues Telecom for real time data integration its features made it the evident candidate for the future System In this talk we’ll present a real use case of streaming analytics using Flink Kafka HBase along with other legacy systems\tFlink Forward 2016: Mohamed ABDESSEMED & T. Lamirault - A brief history of time with Apache Flink\nid:youtube:post:_qWs_rMUKPQ\t2016-09-20T09:57:21.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions running apache flink everywhere standalone yarn mesos docker kubernetes etc The world of cluster managers and deployment frameworks is getting complicated There is zoo of tools to deploy and manage data processing jobs all of which have different resource management and fault tolerance slightly different Some tools have a only per job processes Yarn Docker Kubernetes while others require some long running processes Mesos Standalone In some frameworks streaming jobs control their own resource allocation Yarn Mesos while for other frameworks resource management is handled by external tools Kubernetes To be broadly usable in a variety of setups Flink needs to play well with all these frameworks and their paradigms This talk describes Flink s new proposed process and deployment model that will make it work together well with the above mentioned frameworks The new abstraction is designed to cover a variety of use cases like isolated single job deployments sessions of multiple short jobs and multi tenant setups\tFlink Forward 2016: Stephan Ewen - Running Apache Flink everywhere\nid:youtube:post:w9f-440oejg\t2016-09-20T09:37:54.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions blink improvements to flink and its application in alibaba search A large portion of transactions on Alibaba’s e commerce Taobao platform is initiated through its Alibaba Search engine Real time data streaming processing is one of the cornerstones in Alibaba’s search infrastructure Among all the streaming solutions Flink is the closest to meet our requirements However we don’t think Flink is quite up to our scale and reliability challenges For example its current support for Yarn can result in inefficiency in resource allocation Job isolation and debugging can also be challenging In this paper we present the design and implementation of Blink an improved runtime engine for Flink better integrated with Yarn It addresses above and various other problems we encountered in production Since the changes are at the runtime layer Blink is fully compatible with the Flink API and its machine learning libraries We will also share the experience in our production use in a Hadoop cluster of more than one thousand servers in Alibaba Search\tFlink Forward 2016: Xiaowei Jiang - Blink: Improvements to Flink & its application in Alibaba Search\nid:youtube:post:RJ3JNpzI9vk\t2016-09-20T09:20:36.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions beaming flink to the cloud netflix Netflix is a data driven company and we process over 700 billion streaming events per day with at least once processing semantics in the cloud To enable extracting intelligence from this unbounded stream easily we are building Stream Processing as a Service SPaaS infrastructure so that the user can focus on extracting value and not have to worry about boilerplate infrastructure and scale We will share our experience in building a scalable SPaaS using Flink Apache Beam and Kafka as the foundation layer to process over 1 3 PB of event data without service disruption\tFlink Forward 2016: Monal Daxini - Beaming Flink to the Cloud @ Netflix\nid:youtube:post:oPorLtfOB4o\t2016-09-20T09:06:11.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions the future of apache flinktm In this session we will first have a look at the current state of Apache Flink before diving into some of the upcoming features that are either already in development or still in the design phase Some of the features currently in development that we are going to cover are Dynamic Scaling Adapting a running program to changing workloads Queryable State External querying of internal Flink state This has the power to replace key value stores by turning Flink into a key value store that allows for up to date querying of results Side Inputs Having additional data that evolves over time as input to a stream operation For the glimpse at the far off future of Apache Flink we dare not make any predictions yet In the session we will look at the latest whisperings and see what the community is currently thinking up as solutions to existing problems and predicted future challenges in the stream processing space\tFlink Forward 2016: Aljoscha Krettek -  The Future of Apache Flink\nid:youtube:post:ACS6OM1-xgE\t2016-09-20T08:47:24.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions robust stream processing with apache flink In this hands on talk and demonstration I’ll give a very short introduction to stream processing and then dive into writing code and demonstrating the features in Apache Flink that make truly robust stream processing possible We’ll focus on correctness and robustness in stream processing During this live demo we’ll be developing a realtime analytics application and modifying it on the fly based on the topics we’re working though We’ll exercise Flink’s unique features demonstrate fault recovery clearly explain and demonstrate why Event Time is such an important concept in robust stateful stream processing and talk about and demonstrate the features you need in a stream processor in production Some of the topics covered will be – Stateful Stream Processing – Event Time vs Processing Time – Fault tolerance – State management in the face of faults – Savepoints – Data re processing – Planned downtime and upgrades\tFlink Forward 2016: Jamie Grier - Robust Stream Processing with Apache Flink\nid:youtube:post:UrRQYzux5L0\t2016-09-20T08:26:55.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\thttp flink forward org kb_sessions joining infinity windowless stream processing with flink The extensive set of high level Flink primitives makes it easy to join windowed streams However use cases that don’t have windows can prove to be more complicated making it necessary to leverage operator state and low level primitives to manually implement a continuous join This talk will focus on the anomalies that present themselves when performing streaming joins with infinite windows and the problems encountered operating topologies that back user facing data We will describe the approach taken at ResearchGate to implement and maintain a consistent join result of change data capture streams\tFlink Forward 2016: Sanjar Akhmedov -  Joining Infinity: Windowless Stream Processing with Flink\nid:youtube:post:ZBCXXiDr3TU\t2016-03-01T14:16:52.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 2015 at Kulturbrauerei Berlin\tFlink Forward 2015: Vasia Kalavri – Automatic Detection of Web Trackers\nid:youtube:post:RgrJ3EcNIVo\t2016-02-11T14:57:36.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Berlin Meetup 10 26 08 15 Large Scale Graph Processing with Apache Flink by Andra Lungu\t26.08.15 Apache Flink Berlin Meetup #10 Andra Lungu\nid:youtube:post:Rk8mVtGumPc\t2016-02-11T14:57:34.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Berlin Meetup 13 26 01 16 Implementing BigPetStore by Márton Balassi\t26.01.16  Apache Flink Berlin Meetup #13 Márton Balassi\nid:youtube:post:P3zAw4quJ5k\t2016-02-10T10:46:57.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Community Update Roadmap 2016 by Robert Metzger Berlin 26 01 2016\tApache Flink Meetup Berlin #13, 26.01.16 Community Update R. Metzger\nid:youtube:post:4F4-ea1-v9o\t2015-12-18T13:07:34.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tModern Effective Apache Mesos by Jörg Schad from Mesosphere\tApache Flink Meetup Berlin #12 Modern Effective Apache Mesos\nid:youtube:post:1Y8zgLn1HTo\t2015-12-18T12:48:43.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Comminity Update 16 12 2015 by Robert Metzger\tApache Flink Meetup Berlin #12 Community Update\nid:youtube:post:Gs-Bl_HEY4A\t2015-11-13T14:09:54.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Kostas Tzoumas & Stephan Ewen – Apache Flink: from incubation to Flink 1.0\nid:youtube:post:y7f6wksGM6c\t2015-11-13T13:31:08.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: William Vambenepe – Google Cloud Dataflow and Flink\nid:youtube:post:r8sqwho6otY\t2015-11-13T12:47:45.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Assaf Araki – Smart Data Pipes for the Internet of Things new\nid:youtube:post:hJQr_9jb2qk\t2015-11-13T12:28:21.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin Please note we had to re tape Kamals presentation due to a technical issue during recording\tFlink Forward: Kamal Hakimzadeh – Karamel - Reproducing distributed systems and experiments on cloud\nid:youtube:post:yozcWRyq2g4\t2015-11-13T11:33:56.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Stefano Bortoli & Flavio Pompermaier – A Semantic Big Data Companion\nid:youtube:post:SVnRFrEYE3s\t2015-11-12T17:36:14.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Nam Luc Tran – Stale Synchronous Parallel Iterations on Flink\nid:youtube:post:OHAv6o2fCi8\t2015-11-12T16:32:22.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Slim Baltagi – Flink and Spark Similarities and Differences\nid:youtube:post:GxnJ7m5NDNY\t2015-11-12T16:32:17.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Marton Balassi – Stateful Stream Processing\nid:youtube:post:Ef7LhYKftS8\t2015-11-12T15:48:07.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Jim Dowling – Interactive Flink Analytics with Hopsworks and Apache Zeppelin\nid:youtube:post:5ZgJquofKI4\t2015-11-12T15:47:56.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Maximilian Michels – Training DataSet API Hands On and FlinkML\nid:youtube:post:9t_nBkBgYn0\t2015-11-12T15:47:45.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Aljoscha Krettek – Training DataStream API Hands On 2\nid:youtube:post:T7hiwcwCXGI\t2015-11-12T15:47:37.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Aljoscha Krettek – Training DataStream API Hands On 1\nid:youtube:post:x_lR5wVxLHM\t2015-11-12T15:04:43.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Fabian Hueske – Training Intro & System Setup\nid:youtube:post:t7d_P7b8aFw\t2015-11-12T11:40:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Vyacheslav Zholudev – Flink a convenient abstraction layer for YARN\nid:youtube:post:cnqPyw_uQAQ\t2015-11-12T11:40:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Christian Kreutzfeld – Static vs Dynamic Stream Processing\nid:youtube:post:l0CmYzz1Oxg\t2015-11-12T11:23:29.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Anwar Rizal – Implementing Streaming Decision Tree\nid:youtube:post:QnvaxtCsAzs\t2015-11-12T10:41:31.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Ignacio Mulas Viela – Applying Kappa Architecture in the Telecom Industry\nid:youtube:post:hjmgZfXSi3M\t2015-11-12T10:14:12.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Mohammed Amine – Real time data integration with Flink &  Kafka\nid:youtube:post:8qptr8BJ4GQ\t2015-11-11T14:46:52.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Michael Häusler – Everyday Flink\nid:youtube:post:v_exWHj1vmo\t2015-11-10T16:34:21.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Dongwon Kim – A comparative performance evaluation of Flink\nid:youtube:post:ddVTZSNhCdo\t2015-11-10T12:53:50.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Mikio Braun – Procedural Programming vs  Data Flow\nid:youtube:post:xiKsOocNkDA\t2015-11-09T13:54:22.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Aljoscha Krettek – Notions of Time\nid:youtube:post:9M09bZ6TjcM\t2015-11-09T10:59:13.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Fabian Hueske – Juggling with Bits and Bytes\nid:youtube:post:UV6vP0IB17A\t2015-11-09T10:59:11.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Till Rohrmann –  Fault Tolerance and Recovery of Flink Jobs\nid:youtube:post:hRCE82J2fXE\t2015-11-09T07:46:38.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Christopher Hillman – Beyond MapReduce, Scientific data processing in real time\nid:youtube:post:an-rKMpTKR0\t2015-11-09T07:45:50.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Alexander Kolb – Flink Yet another streaming framework\nid:youtube:post:WmP9xB_sG2o\t2015-11-06T16:13:13.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Martin Junghanns – Gradoop Scalable Graph Analytics with Apache Flink\nid:youtube:post:c-L7R9WH2aM\t2015-11-02T15:14:11.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 2015 at Kulturbrauerei Berlin\tFlink Forward 2015: Ufuk Celebi – Apache Flink’s Streaming Data Flow\nid:youtube:post:K3ugWmHb7CE\t2015-11-01T18:41:16.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Maximilian Michaels – Google Cloud Dataflow on top of Apache Flink\nid:youtube:post:aGQQkO83Ong\t2015-11-01T18:40:15.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Matthias Sax – A tale of Squirrels and Storms\nid:youtube:post:_Jf8yAy5WR8\t2015-11-01T14:43:59.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: M. Schwering – Flink with MongoDB to enhance relevancy in personalization\nid:youtube:post:G7JlpARrFkU\t2015-11-01T12:55:56.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Fabian Hueske – Cascading on Flink\nid:youtube:post:T6Er2ssAZFc\t2015-10-31T18:27:53.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Suneel Marthi – BigPetStore A Comprehensive Blueprint for Apache Flink\nid:youtube:post:icyOTyteMqs\t2015-10-31T18:27:09.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Moon soo Lee – Data science lifecycle with Apache Flink and Apache Zeppelin\nid:youtube:post:neEDkbRptNw\t2015-10-31T18:26:08.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Albert Bifet – SAMOA Mining Big Data Streams with Apache Flink\nid:youtube:post:Uh92PK0K0mA\t2015-10-31T18:25:06.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Sebastian Schelter – Declarative Machine Learning with the Samsara DSL\nid:youtube:post:CaObaAv9tLE\t2015-10-31T09:15:26.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tFlink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin\tFlink Forward 2015: Simon Laws – Apache Flink cluster deployment on Docker using Docker Compose\nid:youtube:post:J56z0YGYZ6w\t2015-09-23T13:26:50.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 10 26 08 15 Slides can be found here http de slideshare net robertmetzger1 august flink community update\tApache Flink Meetup #10 Community Update by Robert Metzger 26.08.2015\nid:youtube:post:hQEcVmKaaMs\t2015-08-06T13:25:01.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup 9 29 07 2015 Find the slides here http de slideshare net AljoschaKrettek flink 010 upcoming features\tApache Flink Meetup #9 Upcoming Features – Aljoscha Krettek 29.07.2015\nid:youtube:post:p-6oompVwjU\t2015-08-06T12:23:17.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 9 29 07 15 Slides can be found here http de slideshare net robertmetzger1 flink cummunity update july berlin meetup\tApache Flink Meetup #9 Community Update by Robert Metzger 29.07.2015\nid:youtube:post:mQes7I2QMUY\t2015-07-09T13:12:32.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 8 23 06 15 Slides http www slideshare net MrtonBalassi flink communityupdatejune Blog http data artisans com flink at bouygues html Apache Flink Committer Marton Balassi gives the monthly Community Update at the eigth Apache Flink Meetup in Berlin https flink apache org http data artisans com\tApache Flink Community Update #8 by Marton Balassi 23.06.15\nid:youtube:post:6BjoW2Vs2C0\t2015-07-09T13:12:12.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tSlides http de slideshare net mikiobraun flink meetup2015 Apache Flink meetup Berlin 23 06 15 Talk by Mikio Braun Data flow vs procedural programming How to put your algorithms into Flink Modern Big Data frameworks including Flink are often based on a data flow programming model The main data type is a set and an algorithm must be formulated in terms of transformations on these sets dealing with one element at a time This is in stark contrast to classical programming languages which are based on variables functions and control flow like for loops and conditional statements to process data Mikio will discuss both approaches and show how to translate a more classical piece of code into the data flow formalism to be able to benefit from the scalability of these systems https flink apache org http data artisans com\tData flow vs. procedural programming: How to put your algorithms into Flink  by Mikio Braun 23.06.15\nid:youtube:post:YI3qdjKop3s\t2015-06-03T22:26:02.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 27 05 15 Slides http www slideshare net fhueske how Blog post https flink apache org news 2015 05 A common challenge that all JVM based data analytics engines such as Apache Flink face is to store large amounts of data in memory to enable efficient sorting and joining The most straight forward approach to process on lots of data in a JVM is to put it as objects on the heap and operate on these objects However this approach has a few notable drawbacks In this talk Fabian will explain in detail how Flink actively manages its memory serializes objects into binary representations and efficiently operates on this data He will also show some numbers comparing the performance of sorting objects on the heap and sorting them in a serialized format https flink apache org http data artisans com\tJuggling with Bits and Bytes - How Apache Flink operates on binary data - Fabian Hueske\nid:youtube:post:UEkjRN8jRx4\t2015-06-01T11:57:08.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 27 05 15 Slides http de slideshare net robertmetzger1 apache flink hands on Over the past years we ve seen many new Flink users In this talk Robert will answer the most frequent asked questions The talk is interesting for both new and existing Flink users New users will get a good overview of the system from a user s perspective and existing users will probably find some hidden gems in the talk\tHands on Apache Flink by Robert Metzger\nid:youtube:post:9-FyOPoZ-VY\t2015-05-28T17:08:22.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 7 27 05 15 Slides http de slideshare net robertmetzger1 berlin apache flink meetup may 2015 community update Apache Flink Committer Robert Metzger gives his monthly Community Update at the seventh Apache Flink Meetup in Berlin https flink apache org http data artisans com\tApache Flink Community Update #7 by Robert Metzger\nid:youtube:post:oSCOf0lgRQI\t2015-05-02T16:36:27.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 6 29 04 15 Slides http www slideshare net ucelebi apache flink meetup berlin 6 unified batch stream processing in apache flink Apache Flink Committer Ufuk Celebi gives an overview of Flink s runtime Ufuk explains how Flink runs your programs and what happens internally giving a deeper understanding of Flink s low level internals and how you can tweak your programs to make the most out of it https flink apache org http data artisans com\tApache Flink's Unified Batch & Stream Processing by Ufuk Celebi\nid:youtube:post:OcoYFFVNp1o\t2015-05-02T16:36:06.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tSlides http www slideshare net FrankMcSherry flink meetup Apache Flink Meetup Berlin 6 29 04 15 Frank surveys some recent research work from his experience with the Naiad project on extended dataflow models including those integrating streaming and iterative computation The material is not specific to Flink but it should be interesting for anyone looking to push the boundaries of dataflow computation https flink apache org\tHot Topics in Data Flow by Frank McSherry @ Apache Flink Meetup Berlin\nid:youtube:post:kQR5Jfds3h4\t2015-05-02T16:32:47.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\tApache Flink Meetup Berlin 6 29 04 15 Slides http www slideshare net robertmetzger1 flink communityupdate 47595784 Apache Flink Committer Robert Metzger gives his monthly Community Update at the sixth Apache Flink Meetup in Berlin https flink apache org http data artisans com\tApache Flink Community Update #6    29.04.15 by Robert Metzger\nid:youtube:post:fw2DBE6ZiEQ\t2015-04-01T19:01:27.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\t31 03 15 Slides http www slideshare net stephanewen1 flink history roadmap and vision Apache Flink Committer Stephan Ewen gives a talk about Apache Flink s History and Vision during the Apache Flink Meetup in Berlin In April 2014 Flink back then called Stratosphere was proposed as an incubating project to the Apache Software Foundation Nine months later Flink graduated to an Apache top level project To commemorate one year of Flink 1 We first take a trip down memory lane and discuss what the Flink community has built during the last year in the Apache Software Foundation 2 We then discuss the roadmap for the Flink project for 2015 and current work in progress features such as the runtime refactoring to include intermediate results and streaming fault tolerance 3 Finally we discuss the greater vision and goals of the Flink project and how the current roadmap leads to realizing this vision https flink apache org http data artisans com\tHistory and Vision of Apache Flink by Stephan Ewen\nid:youtube:post:qyl2GiebsJ8\t2015-04-01T18:26:11.000Z\tid:youtube:UCY8_lgiZLZErZPF47a2hXMA\tApache Flink Berlin\t31 03 15 Slides http www slideshare net robertmetzger1 apache flink community update march 2015 Apache Flink Committer Robert Metzger gives his monthly Community Update at the Apache Flink Meetup in Berlin https flink apache org http data artisans com\tApache Flink Community Update #5 by Robert Metzger\n","comment":"","msgTable":[[{"key":"published","value":"id:youtube:post:RYoFwQFvC_g"},{"key":"published","value":"2016-11-17T14:29:43.000Z"},{"key":"published","value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"key":"published","value":"Apache Flink Berlin"},{"key":"published","value":"Two days of conference One day of training More than 350 attendees from all over the globe over 40 international speakers 3 stages and lots of squirrels – At Flink Forward Berlin we’ve enjoyed three days full of exciting training sessions keynotes technical talks and panels It was the second Flink Forward organized by data Artisans and we want to thank you for trusting us and making next year’s conferences in San Francisco and Berlin a blast droidcon Berlin – http droidcon de Facebook https www facebook com dr Google+ https plus google com +dr Twitter https twitter com droidconDE Instagram https instagram com droid LinkedIn https www linkedin com gr XING https www xing com commun Find more information on all droidcons worldwide on http droidcon com"},{"key":"published","value":"A taste of Flink Forward"}],[{"key":"id","value":"id:youtube:post:inFPmLV6FPI"},{"key":"id","value":"2016-09-27T15:38:10.000Z"},{"key":"id","value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"key":"id","value":"Apache Flink Berlin"},{"key":"id","value":"Jamie Grier Director of Applications Engineering at data Artisans talks about his work at data Artisans and the Apache Flink projects he is involved with"},{"key":"id","value":"Interview with Jamie Grier, Director of Applications Engineering at data Artisans"}],[{"key":"displayName","value":"id:youtube:post:TI-uQtB57D4"},{"key":"displayName","value":"2016-09-27T15:31:11.000Z"},{"key":"displayName","value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"key":"displayName","value":"Apache Flink Berlin"},{"key":"displayName","value":"Márton Balassi Solutions Architect at Cloudera talks about his work and the Apache Flink community"},{"key":"displayName","value":"Interview with Márton Balassi, Solutions Architect at Cloudera"}],[{"key":"content","value":"id:youtube:post:LvFcTedwpiI"},{"key":"content","value":"2016-09-27T15:23:38.000Z"},{"key":"content","value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"key":"content","value":"Apache Flink Berlin"},{"key":"content","value":"Gyula Fóra Data Warehouse Engineer at King talks about his work and the most exciting Flink features to come"},{"key":"content","value":"Interview with Gyula Fóra, Data Warehouse Engineer at King"}],[{"key":"title","value":"id:youtube:post:6uvrWMbZ6xQ"},{"key":"title","value":"2016-03-23T09:40:41.000Z"},{"key":"title","value":"id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ"},{"key":"title","value":"Apache Syncope"},{"key":"title","value":"http syncope tirasa net news apache syncope 2 0 0 dashboard html"},{"key":"title","value":"Apache Syncope 2.0.0 Dashboard"}],[{"value":"id:youtube:post:-VMoF70hwSA"},{"value":"2016-09-27T15:19:36.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Ted Dunning Chief Application Architect at MapR Technologies talks about his work and his first involvement in Apache Flink"},{"value":"Interview with Ted Dunning, Chief Application Architect at MapR Technologies"}],[{"value":"id:youtube:post:ARJLp6xhKo8"},{"value":"2016-09-27T15:11:45.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Maxim Fateev staff engineer at Uber talks about his projects at Uber and his experiences with Apache Flink"},{"value":"Interview with Maxim Fateev, staff engineer at Uber"}],[{"value":"id:youtube:post:xxKzjV2vmSA"},{"value":"2015-10-12T15:14:02.000Z"},{"value":"id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ"},{"value":"Apache Syncope"},{"value":"http syncope tirasa net news apache syncope 2 0 0 and swagger html"},{"value":"Apache Syncope 2.0.0 and Swagger UI"}],[{"value":"id:youtube:post:vl7Q2lKyPn8"},{"value":"2015-08-13T10:48:25.000Z"},{"value":"id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ"},{"value":"Apache Syncope"},{"value":"http syncope tirasa net news apache syncope 2 0 resource management html"},{"value":"Apache Syncope console 2.0 - Work in progress"}],[{"value":"id:youtube:post:EAFsq7QwFAc"},{"value":"2016-09-26T12:50:50.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Aljoscha Krettek stepped in for Robert Metzger http flink forward org kb_sessions connecting apache flink with the world reviewing the streaming connectors Getting data in and out of Flink in a reliable fashion is one of the most important tasks of a stream processor This talk will review the most important and frequently used connectors in Flink Apache Kafka and Amazon Kinesis Streams both fall into the same category of distributed high throughput and durable publish subscribe messaging systems The talk will explain how the connectors in Flink for these systems are implemented In particular we’ll focus on how we ensure exactly once semantics while consuming data and how offsets sequence numbers are handled We will also review two generic tools in Flink for connectors A message acknowledging source for classical message queues like those implementing AMQP and a generic write ahead log sink using Flink’s state backend abstraction The objective of the talk is to explain the internals of the streaming connectors so that people can understand their behavior configure them properly and implement their own connectors"},{"value":"Flink Forward 2016: Aljoscha Krettek - Connecting Apache Flink to the World..."}],[{"value":"id:youtube:post:2MWn7DlCfjY"},{"value":"2014-05-28T13:03:36.000Z"},{"value":"id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ"},{"value":"Apache Syncope"},{"value":""},{"value":"Syncope Compliance Dashboard - Connectors Status"}],[{"value":"id:youtube:post:e-9Z_213_ZU"},{"value":"2016-09-26T12:37:24.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions to petascale and beyond apache flink in the clouds Apache Flink performs with low latency but can also scale to great heights Gelly is Flink s laboratory for building and tuning scalable graph algorithms and analytics In this talk we ll discuss writing algorithms optimized for the Flink architecture assembling and configuring a cloud compute cluster and boosting performance through benchmarking and system profiling This talk will cover recent developments in the Gelly library to include scalable graph generators and a mixed collection of modular algorithms written with native Flink operators We ll think like a data stream keep a cool cache and send the garbage collector on holiday To this we ll add a lightweight benchmarking harness to stress and validate core Flink and to identify and refactor hot code with aplomb"},{"value":"Flink Forward 2016: Greg Hogan -To Petascale and Beyond: Apache Flink in the Clouds"}],[{"value":"id:youtube:post:ahgu59FqhrM"},{"value":"2014-05-28T12:58:32.000Z"},{"value":"id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ"},{"value":"Apache Syncope"},{"value":""},{"value":"Syncope Compliance Dashboard - Architecture Overview"}],[{"value":"id:youtube:post:L21N8mNtvME"},{"value":"2016-09-26T12:32:07.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions multi tenant flink as a service on yarn Since June 2016 Flink as a service has been available to researchers and companies in Sweden from the Swedish ICT SICS Data Center at www hops site using the HopsWorks platform Flink applications can be either deployed as jobs batch or streaming or written and run directly from Apache Zeppelin on YARN Flink applications are run within a project on a YARN cluster with the novel property that Flink applications are metered and charged to projects Projects are also securely isolated from each other and include support for project specific Kafka topics that are protected from access by users that are not members of the project Hopsworks is entirely UI driven is open source and Flink applications that include Kafka topics can be created in a few mouse clicks In this talk we will discuss the challenges in building a metered version of Flink as a Service for YARN experiences with Flink on YARN and some of the possibilities that Hopsworks opens up for building secure multi ten"},{"value":"Flink Forward 2016: Jim Dowling - Multi-tenant Flink-as-a-Service on YARN"}],[{"value":"id:youtube:post:uscx9MrSKWY"},{"value":"2016-09-26T12:17:12.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions code generation in serializers and comparators of apache flink Performance of Big Data applications are often limited by serializers and comparators In the case of Flink despite its delicate type system hand writing serializers leads to a 10 improvement for a simple WordCount job using Pojos There are applications where the gain can be even more about 30 A significant amount of the overhead is the result of using reflection to access the fields of Pojo objects There is some additional overhead due to the fact that the JVM has a hard time to optimize the current default serializers and comparators because of their dynamic nature In order to improve the performance I implemented runtime code generation to generate specialized code for each Pojo type at runtime to improve the performance The generated code accesses fields without reflection and easier to optimize In the talk I will give a detailed overview of the challenges of implementing code generation the solutions and some measurements about the performance improvements"},{"value":"Flink Forward 2016: Gábor Horváth - Code Generation in Serializers and Comparators of Apache Flink"}],[{"value":"id:youtube:post:BZJnNfSBdQ8"},{"value":"2016-09-26T12:11:01.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions flink security enhancements Recent security enhancements to Flink make it easy to access secure data and to protect the associated credentials In this talk we’ll describe and demonstrate the new features including Kerberos based access to HDFS and Kafka transport security TLS and service level authorization which protects your Flink cluster from unauthorized access"},{"value":"Flink Forward 2016: Eron Wright -  Flink Security Enhancements"}],[{"value":"id:youtube:post:nXQvBy_onfs"},{"value":"2016-09-26T12:10:47.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions introducing flink on mesos Apache Flink supports a variety of deployment modes with support for Apache Mesos new to Flink 1 2 This talk will cover the benefits and major features of Flink on Mesos We’ll demonstrate the functionality and discuss future directions"},{"value":"Flink Forward 2016: Eron Wright - Introducing Flink on Mesos"}],[{"value":"id:youtube:post:TKcnMA7fn-s"},{"value":"2016-09-26T12:08:01.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions taking a look under the hood of apache flinks relational apis Apache Flink features two APIs which are based on relational algebra a SQL interface and the so called Table API which is a LINQ style API available for Scala and Java Relational APIs are interesting because they are easy to use and queries can be automatically optimized and translated into efficient runtime code Flink offers both APIs for streaming and batch data sources This talk will take a look under the hood of Flink’s relational APIs We will show the unified architecture to handle streaming and batch queries and explain how Flink translates queries of both APIs into the same representation leverages Apache Calcite to optimize them and generates runtime code for efficient execution Finally we will discuss potential improvements and give an outlook for future extensions and features"},{"value":"Flink Forward 2016: Fabian Hueske - Taking a look under the hood of Apache Flink’s relational APIs"}],[{"value":"id:youtube:post:vws5bv3XdD8"},{"value":"2016-09-26T12:06:31.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions declarative stream processing with streamsql and cep Complex event processing CEP and stream analytics are commonly treated as distinct classes of stream processing applications While CEP workloads identify patterns from event streams in near real time stream analytics queries ingest and aggregate high volume streams Both types of use cases have very different requirements which resulted in diverging system designs CEP systems excel at low latency processing whereas engines for stream analytics achieve high throughput Recent advances in open source stream processing yielded systems that can process several millions of events per second at sub second latency Systems like Apache Flink enable applications that include typical CEP features as well as heavy aggregations In this talk we will show how Apache Flink unifies CEP and stream analytics workloads Guided by examples we introduce Flink’s CEP enriched StreamSQL interface and discuss how queries are compiled optimized and executed on Flink"},{"value":"Flink Forward 2016: Fabian Hueske & Till Rohrmann - Declarative stream processing..."}],[{"value":"id:youtube:post:uuv-lnOrD0o"},{"value":"2016-09-26T11:06:38.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions the stream processor as a database building online applications directly on streams We present a new design pattern for data streaming applications using Apache Flink and Apache Kafka Building applications directly on top of the stream processor rather than on top of key value databases populated by data streams Unlike classical setups that use stream processors or libraries to pre process aggregate events and update a database with the results this setup simply gives the role of the database to the stream processor here Apache Flink routing queries to its workers who directly answer them from their internal state computed over the log of events Apache Kafka This talk will cover both the high level introduction to the architecture the techniques in Flink Kafka that make this approach possible as well as experiences from a large scale setup and technical details"},{"value":"Flink Forward 2016: Jamie Grier - The Stream Processor as a Database"}],[{"value":"id:youtube:post:3ySKJN5bbjk"},{"value":"2016-09-26T10:45:41.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions dynamic scaling how apache flink adapts to changing workloads Modern stream processing engines not only have to process millions of events per second at sub second latency but also have to cope with constantly changing workloads Due to the dynamic nature of stream applications where the number of incoming events can strongly vary with time systems cannot reliably predetermine the amount of required resources In order to meet guaranteed SLAs as well as utilizing system resources as efficiently as possible frameworks like Apache Flink have to adapt their resource consumption dynamically In this talk we will take a look under the hood and explain how Flink scales stateful application in and out Starting with the concept of key groups and partionable state we will cover ways to detect bottlenecks in streaming jobs and discuss efficient strategies how to scale out operators with minimal down time"},{"value":"Flink Forward 2016: Till Rohrmann - Dynamic Scaling - How Apache Flink adapts to changing workloads"}],[{"value":"id:youtube:post:17tUR4TsvpM"},{"value":"2016-09-26T10:33:49.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions rbea scalable real time analytics at king This talk introduces RBEA Rule Based Event Aggregator the scalable real time analytics platform developed by King’s Streaming Platform team We have built RBEA to make real time analytics easily accessible to game teams across King without having to worry about operational details RBEA is built on top of Apache Flink and uses the framework s capabilities to it s full potential in order to provide highly scalable stateful and windowed processing logic for the analytics applications We will talk about how we have built a high level DSL on the abstractions provided by Flink and how we tackled different technical challenges that have come up while developing the system"},{"value":"Flink Forward 2016: Gyula Fóra - RBEA- Scalable Real-Time Analytics at King"}],[{"value":"id:youtube:post:udQcdwa8jbg"},{"value":"2016-09-26T10:22:08.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions flink in zalandos world of microservices In this talk we present Zalando s microservices architecture introduce Saiki – our next generation data integration and distribution platform on AWS and show how we employ stream processing with Apache Flink for near real time business intelligence Zalando is one of the largest online fashion retailers in Europe In order to secure our future growth and remain competitive in this dynamic market we are transitioning from a monolithic to a microservices architecture and from a hierarchical to an agile organization We first have a look at how business intelligence processes have been working inside Zalando for the last years and present our current approach Saiki It is a scalable cloud based data integration and distribution infrastructure that makes data from our many microservices readily available for analytical teams We no longer live in a world of static data sets but are instead confronted with endless streams of events that constantly inform us about relevant happenings from all over the enterprise The processing of these event streams enables us to do near real time business intelligence In this context we have evaluated Apache Flink vs Apache Spark in order to choose the right stream processing framework Given our requirements we decided to use Flink as part of our technology stack alongside with Kafka and Elasticsearch With these technologies we are currently working on two use cases a near real time business process monitoring solution and streaming ETL Monitoring our business processes enables us to check if technically the Zalando platform works It also helps us analyze data streams on the fly e g order velocities delivery velocities and to control service level agreements On the other hand streaming ETL is used to relinquish resources from our relational data warehouse as it struggles with increasingly high loads In addition to that it also reduces the latency and facilitates the platform scalability Finally we have an outlook on our future use cases e g near real time sales and price monitoring Another aspect to be addressed is to lower the entry barrier of stream processing for our colleagues coming from a relational database background"},{"value":"Flink Forward 2016: Javier Lopez & Mihail Vieru - Flink in Zalando's World of Microservices"}],[{"value":"id:youtube:post:X83rmmb6rgs"},{"value":"2016-09-26T10:06:56.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions apache beam a unified model for batch and streaming data processing Unbounded unordered global scale datasets are increasingly common in day to day business and consumers of these datasets have detailed requirements for latency cost and completeness Apache Beam incubating defines a new data processing programming model that evolved from more than a decade of experience within Google including MapReduce FlumeJava MillWheel and Cloud Dataflow Beam handles both batch and streaming use cases and neatly separates properties of the data from runtime characteristics allowing pipelines to be portable across multiple runtimes both open source e g Apache Flink Apache Spark et al and proprietary e g Google Cloud Dataflow This talk will cover the basics of Apache Beam touch on its evolution describe main concepts in the programming model and compare with similar systems We’ll go from a simple scenario to a relatively complex data processing pipeline and finally demonstrate execution of that pipeline on multiple runtimes"},{"value":"Flink Forward 2016: Kenneth Knowles -  Apache Beam: A Unified Model for..."}],[{"value":"id:youtube:post:msdjh6KRXC8"},{"value":"2016-09-26T09:50:21.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions flink and beam current state roadmap It is no secret that the Dataflow model which evolved from Google’s MapReduce Flume and MillWheel has been a major influence to Apache Flink’s streaming API The essentials of this model are captured in Apache Beam Beam provides the Dataflow API with the option to deploy to various backends e g Flink Spark In this talk we will examine the current state of the Flink Runner Beam’s Runners manage the translation of the Beam API into the backend API The Beam project itself has made an effort to summarize the capabilities of each Runner to provide an overview of the supported API concepts From all open sources backends Flink is currently the Runner which supports the most features We will look at the supported Beam features and their counterpart in Flink Further we will look at potential improvements and upcoming features of the Flink Runner"},{"value":"Flink Forward 2016: Maximilian Michels - Flink and Beam: Current State & Roadmap"}],[{"value":"id:youtube:post:q9MPTCpWmuM"},{"value":"2016-09-26T09:27:08.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions no shard left behind dynamic work rebalancing in apache beam The Apache Beam incubating programming model is designed to support several advanced data processing features such as autoscaling and dynamic work rebalancing In this talk we will first explain how dynamic work rebalancing not only provides a general and robust solution to the problem of stragglers in traditional data processing pipelines but also how it allows autoscaling to be truly effective We will then present how dynamic work rebalancing works as implemented in Google Cloud Dataflow and which path other Apache Beam runners link Apache Flink can follow to benefit from it"},{"value":"Flink Forward 2016: Malo Denielou – No shard left behind: Dynamic work rebalancing in Apache Beam"}],[{"value":"id:youtube:post:YsWwox7Lnco"},{"value":"2016-09-26T09:07:38.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions flink in genomics efficient and scalable processing of raw illumina bcl data A single run in genome sequencing can easily produce several terabytes of data which subsequently feed a complex pipeline of tools Typically the first step in this workflow is a rearrangement of data roughly equivalent to a matrix transposition to reconstruct the original DNA fragments from the raw BCL data where the fragments are sliced and scattered over multiple files This step is followed by the sorting of the fragments by a specific identifying tag sequence which is attached during the preparation of the sample In this talk we will present a parallel program which performs these essential operations Our BCL converter is shown to have comparable performance to the shared memory Illumina bcl2fastq tool while also enabling easy and scalable distributed memory parallelization We will describe the techniques we have used to achieve high performance and discuss the features of Flink which we have particularly appreciated as well as the ones which we think are still missing"},{"value":"Flink Forward 2016 - Francesco Versaci - Flink in genomics..."}],[{"value":"id:youtube:post:OeHSPPWLeYQ"},{"value":"2016-09-26T08:41:38.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions building a real time tweet map with flink in six weeks It is often necessary to build a proof of concept for a bigdata project to show the feasibility to customers With OSTMap Open Source Tweet Map we proved that it is possible to accomplish this with the right choice of technologies in a short time frame OSTMap enables the user to view live geotagged tweets of the last hours on a map search all collected tweets by a term or user name and view the amount of incoming tweets per minute distinguished by language as a graph With OSTMap we cover several important areas of a typical big data PoC project scalability stream processing and ingest of incoming data batch processing of stored data performant queries on the data and visualization of the data To achieve this we use Apache Flink and Apache Accumulo as backend technologies AngularJS and Leaflet for the frontend OSTMap was developed iteratively using the walking skeleton approach which allowed us to increase the feature set constantly even with a strict deadline"},{"value":"Flink Forward 2016 - Matthias Kricke, Martin Grimmer, Michael Schmeißer – Building a real time..."}],[{"value":"id:youtube:post:k5pvgZUbIZA"},{"value":"2016-09-26T08:27:49.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions advanced visualization of flink and spark jobs Understanding the physical plan of a big data application is often crucial for tracking down bottlenecks and faulty behavior Flink and Spark although offering useful Web UI components for monitoring and understanding the logical plan of the jobs both lack a tool that helps to understand the physical plan of the scheduler and the possibility to monitor execution at a very low level along with the communication that occur between parallel vertex instances We propose a tool that allows users to real time monitor and later to replay examine job executions on any cluster currently supported by Flink or Spark The tool also offers monitoring of the distribution of keys in a data stream and can lead to optimizing data partitioning across parallel subtasks in the future"},{"value":"Flink Forward 2016: Zoltán Zvara - Advanced visualization of Flink and Spark jobs"}],[{"value":"id:youtube:post:-iWEnSJ_zaQ"},{"value":"2016-09-25T16:23:12.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions faster and furiouser flink drift Not long ago we had the opportunity to test Apache Flink to see just how fast it would go on a moderately realistic task with fast hardware and with a good streaming transport layer underneath Our goal was not so much careful comparison with other software but flat out speed Flink against Flink In the process we learned a lot about what it takes to go fast Some of the lessons were ones that we had “learned” a number of times before – the bottleneck isn’t where you thought it was – copying data is expensive – context switches are expensive – measure twice cut once But there were some real surprises along the way The really important knobs weren’t quite what people say you should turn One of the biggest surprises was the degree to which high performance libraries have threading built into them which makes the actual concurrrency much higher than the apparent concurrency The result was that at least one cluster parameter needed to be adjusted by 30x to get real"},{"value":"Flink Forward 2016: Ted Dunning - Faster and Furiouser: Flink Drift"}],[{"value":"id:youtube:post:oVDSi30U7rw"},{"value":"2016-09-25T14:19:25.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions apache zeppelin a friendlier way to flink In this talk we present Apache Zeppelin notebook based web UI for working with several big data platforms including Flink In this talk we will show how to leverage several of Zeppelin’s exciting features using Flink The talk demo will be a series of examples of increasing complexity Starting with the obligatory word count example we will move on to loading additional jars to perform machine learning tasks using FlinkML we will do some examples of graph processing in Gelly and visualizing those graphs using AngularJS and d3js both native to Zeppelin give examples of how Zeppelin’s “ResourcePools” can be used to share variables between interpreters leading in to a Flink Streaming Example where variables a “bound” and visualizations update in real time pre supposes working stable Flink Streaming in REPL editors feel free to delete this comment once that has been achieved"},{"value":"Flink Forward 2016: Trevor Grant -  Apache Zeppelin: A friendlier way to Flink"}],[{"value":"id:youtube:post:FtzXOLhZ-2c"},{"value":"2016-09-25T11:52:36.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions streaming ml with flink As continuous big data processing is gaining popularity it naturally implies that there is a need to transition many of the distributed machine learning functionality to a streaming backend The most common use case is to give streaming predictions based on the model learnt in batch however in some cases it is beneficial to also update the model on the fly It is not uncommon that streaming learners need different algorithms than their batch counterparts The talk discusses the common use cases and the pitfalls of the streaming ML transition through the example of recommender systems It also offer a dive into the implementation of a Scala library augmenting FlinkML with streaming predictors"},{"value":"Flink Forward 2016: Márton Balassi - Streaming ML with Flink"}],[{"value":"id:youtube:post:k8RIjuwqIds"},{"value":"2016-09-25T09:36:51.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions streaming sql Streaming is necessary to handle data rates and latency but SQL is unquestionably the lingua franca of data Is it possible to combine SQL with streaming and if so what does the resulting language look like Apache Calcite is extending SQL to include streaming and Apache Flink is using Calcite to support both regular and streaming SQL In this talk Julian Hyde describes streaming SQL in detail and shows how you can use streaming SQL in your application He also describes how Calcite’s planner optimizes queries for throughput and latency"},{"value":"Flink Forward 2016: Julian Hyde - Streaming SQL"}],[{"value":"id:youtube:post:rbvTVQNY8UQ"},{"value":"2016-09-25T07:46:47.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions panel large scale streaming in production As stream processing systems become more mainstream companies are looking to empower their users to take advantage of this technology Stream processing systems promise to allow users to gain valuable data insights in realtime and to simplify and improve common data processing and analytics tasks The scale of stream processing systems can be measured along several dimensions We will focus on two of them in this session The first dimension is data velocity Millions of messages per second is common for some workloads The second dimension is user base Those implementing stream processing systems need to support large and diverse user populations In this session we will have leading experts in the field talk about the challenges they have faced and the solutions they have discovered while implementing stream processing systems at very large scales We will cover the motivations behind these systems discuss the various user groups they serve and discuss the major challenges that need to be addressed Panelists Maxim Fateev Xiaowei Jiang Monal Daxini Ted Dunning Moderated by Jamie Grier"},{"value":"Flink Forward: Panel: Large Scale Streaming in Production"}],[{"value":"id:youtube:post:n679Xa3ZrFo"},{"value":"2016-09-24T17:00:15.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions keynote tba Apache Flink has come a long way from its academic beginnings It is now one of the most technically advanced solutions for streaming computation And batch computation too Flink has serious technical advantages when compared with nearly every alternative system This success ironically means that Apache Flink is right on the cusp of a critical moment Over the next few months it will be decided whether Flink is the Next Big Thing or if it is a fine technology with limited impact Right now what you and I do can make a huge difference But as business people like to say what got Flink here isn’t what’s going to get it there The challenges the Flink community faces now are different from the technical challenges it has met so far I will talk about what I think will help and how we can all pitch in to take Flink forward"},{"value":"Flink Forward 2016: Ted Dunning - Keynote: How Can We Take Flink Forward?"}],[{"value":"id:youtube:post:NI1yN5FbxUM"},{"value":"2016-09-24T12:09:21.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions keynote tba 2 The past 12 months saw the data streaming ecosystem mature and grow tremendously with new open source projects and products being offered in the market and more large scale production applications of streaming data It is now understood that streaming data is not a fad but a growing industry that is here to stay Apache Flink was one of the pioneering communities advocating that stream processing is a great fit for the continuous nature of data production and that batch processing can be seen and efficiently performed as a special case of stream processing Flink saw tremendous growth since the last Flink Forward conference with the project boasting now more than 200 contributors from several companies several production installations and broad adoption In this talk we discuss several large scale stream processing use cases that we see at data Artisans Additionally we discuss what this accelerated growth means for Flink how we can sustain this growth moving forward as well as a vision for the next big directions in Flink"},{"value":"Flink Forward 2016: Kostas Tzoumas & Stephan Ewen - Keynote"}],[{"value":"id:youtube:post:Jexh_GsSWWs"},{"value":"2016-09-20T11:14:10.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":""},{"value":"Kostas Tzoumas - Closing Session"}],[{"value":"id:youtube:post:B2b5qMHA2GI"},{"value":"2016-09-20T11:10:32.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions flinkspector taming the squirrel The costs of logic errors in production for streaming applications are higher than for batch processing systems Depending on the setup errors cannot be rectified or have already influenced important decisions The goal of Flinkspector is to improve the test process of Apache Flink streaming applications in order to detect streaming application logic errors early during development It features dedicated mechanics for test setup execution and evaluation While Flinkspector s streamlined API keeps testing overhead small The framework is able to handle non terminating and parallelized data flows involving windowing The lightweight integration tests enabled by Flinkspector allow Flink applications to be included into the continuous integration and deployment process The talk introduces the core functionality of Flinkspector In addition background concepts of the runtime and the evaluation algorithms are presented https github com ottogroup flink spector"},{"value":"Flink Forward 2016: Alexander Kolb - Flinkspector: Taming the squirrel"}],[{"value":"id:youtube:post:zlU1h0SV4SQ"},{"value":"2016-09-20T10:52:47.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions large scale social network data collection and analysis with apache flink and apache streams Apache Flink offers unparalleled powered and control for streaming applications at scale wrapped in developer friendly Java and Scala SDKs simple to scale up and monitor even for high throughput applications It’s a beast an adorable beast hungry for data and we must feed it Apache Streams incubating unifies a diverse world of digital profiles and online activities into common formats and vocabularies and makes these datasets accessible through standard interfaces hiding the complexity of the underlying APIs and making the data they generate inter compatible by default Streams is the perfect tool to ingest interesting datasets to feed Flink and embedding Streams components within Flink pipelines is dead simple and downright pleasant People Pattern uses Flink and Streams to grow and maintain our database of profiles 200M and growing plus posts and connections from 10+ social networking services including Twitter Instagram Google+ Come learn how we do it"},{"value":"Flink Forward 2016: Steve Blackmon - Large Scale Social Network Data Collection & Analysis..."}],[{"value":"id:youtube:post:uXMmOjFBa94"},{"value":"2016-09-20T10:38:51.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions evaluating streaming framework performance for a large scale aggregation pipeline In this talk I present the results of a set of experiments comparing the performance of several implementations of aggregating time series data There are 3 implementations a baseline implementation not using any streaming frameworks an implementation using Apache Flink and an implementation using Apache Spark Streaming These implementations all ran against the same Kafka cluster using the same data stream with the goal to understand the limitations of the different implementations The limitations were measured at 3 input data rates 100 6000 and breaking point load"},{"value":"Flink Forward 2016: Ron Crocker - Evaluating Streaming Framework Performance for a Large-Scale..."}],[{"value":"id:youtube:post:9mjAPBNl4YM"},{"value":"2016-09-20T10:26:57.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions beyond the watermark on demand backfilling in flink Flink has consistency guarantees and efficient checkpointing model which make it a good fit for Uber’s money related use cases such as driver incentives However Flink’s time progress model is built around a single watermark which is incompatible with Uber’s business need for generating aggregates retroactively The talk covers our solution for on demand backfilling It also outlines other abstractions and features we expect Flink to support as it matures"},{"value":"Flink Forward 2016: Maxim Fateev - Beyond the Watermark: On-Demand Backfilling in Flink"}],[{"value":"id:youtube:post:RvgXt-PIGyI"},{"value":"2016-09-20T10:10:29.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions amidst toolbox scalable probabilistic machine learning with flink In this session we would like to present our AMIDST toolbox for analysis of large scale data sets using probabilistic machine learning models AMIDST runs algorithms in a distributed fashion for learning and inference in a wide spectrum of latent variable models such as Gaussian mixtures probabilistic principal component analysis Hidden Markov Models Kalman Filters Latent Dirichlet Allocation etc This toolbox is able to perform Bayesian parameter learning on any user defined probabilistic graphical model with billions of nodes using novel distributed message passing algorithms We plan to give an overview of the AMIDST toolbox Java open source some details about the API and the integration with Flink and an analysis of the scalability of our learning algorithms All this in the context of a real use case scenario in the financial domain BCC group where the profile of millions of customers is analyzed using Flink and the Amazon Web Services"},{"value":"Flink Forward 2016: Ana M. Martinez - AMIDST Toolbox: Scalable probabil. machine learning w/ Flink"}],[{"value":"id:youtube:post:izYsMQWeUbE"},{"value":"2016-09-20T10:00:35.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions a brief history of time with apache flink real time monitoring and analysis with flink kafka hb Many use cases in the telecommunication industry require producing counters quality metrics and alarms in a streaming fashion with very low latency Most of this metrics are only valuable when they’re made available as soon as the associated events happened In our company we are looking for a system able to produce this kind of real time indicator which must handle massive amounts of data 400 000 eps with often peak loads like New Year’s Eve or out of order events like massive network disorder Low latency and flexible window management with specific watermark emission are also a must haves Heterogeneous format multiple flow correlation and the possibility of late data arrival are other challenges Flink being already widely used at Bouygues Telecom for real time data integration its features made it the evident candidate for the future System In this talk we’ll present a real use case of streaming analytics using Flink Kafka HBase along with other legacy systems"},{"value":"Flink Forward 2016: Mohamed ABDESSEMED & T. Lamirault - A brief history of time with Apache Flink"}],[{"value":"id:youtube:post:_qWs_rMUKPQ"},{"value":"2016-09-20T09:57:21.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions running apache flink everywhere standalone yarn mesos docker kubernetes etc The world of cluster managers and deployment frameworks is getting complicated There is zoo of tools to deploy and manage data processing jobs all of which have different resource management and fault tolerance slightly different Some tools have a only per job processes Yarn Docker Kubernetes while others require some long running processes Mesos Standalone In some frameworks streaming jobs control their own resource allocation Yarn Mesos while for other frameworks resource management is handled by external tools Kubernetes To be broadly usable in a variety of setups Flink needs to play well with all these frameworks and their paradigms This talk describes Flink s new proposed process and deployment model that will make it work together well with the above mentioned frameworks The new abstraction is designed to cover a variety of use cases like isolated single job deployments sessions of multiple short jobs and multi tenant setups"},{"value":"Flink Forward 2016: Stephan Ewen - Running Apache Flink everywhere"}],[{"value":"id:youtube:post:w9f-440oejg"},{"value":"2016-09-20T09:37:54.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions blink improvements to flink and its application in alibaba search A large portion of transactions on Alibaba’s e commerce Taobao platform is initiated through its Alibaba Search engine Real time data streaming processing is one of the cornerstones in Alibaba’s search infrastructure Among all the streaming solutions Flink is the closest to meet our requirements However we don’t think Flink is quite up to our scale and reliability challenges For example its current support for Yarn can result in inefficiency in resource allocation Job isolation and debugging can also be challenging In this paper we present the design and implementation of Blink an improved runtime engine for Flink better integrated with Yarn It addresses above and various other problems we encountered in production Since the changes are at the runtime layer Blink is fully compatible with the Flink API and its machine learning libraries We will also share the experience in our production use in a Hadoop cluster of more than one thousand servers in Alibaba Search"},{"value":"Flink Forward 2016: Xiaowei Jiang - Blink: Improvements to Flink & its application in Alibaba Search"}],[{"value":"id:youtube:post:RJ3JNpzI9vk"},{"value":"2016-09-20T09:20:36.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions beaming flink to the cloud netflix Netflix is a data driven company and we process over 700 billion streaming events per day with at least once processing semantics in the cloud To enable extracting intelligence from this unbounded stream easily we are building Stream Processing as a Service SPaaS infrastructure so that the user can focus on extracting value and not have to worry about boilerplate infrastructure and scale We will share our experience in building a scalable SPaaS using Flink Apache Beam and Kafka as the foundation layer to process over 1 3 PB of event data without service disruption"},{"value":"Flink Forward 2016: Monal Daxini - Beaming Flink to the Cloud @ Netflix"}],[{"value":"id:youtube:post:oPorLtfOB4o"},{"value":"2016-09-20T09:06:11.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions the future of apache flinktm In this session we will first have a look at the current state of Apache Flink before diving into some of the upcoming features that are either already in development or still in the design phase Some of the features currently in development that we are going to cover are Dynamic Scaling Adapting a running program to changing workloads Queryable State External querying of internal Flink state This has the power to replace key value stores by turning Flink into a key value store that allows for up to date querying of results Side Inputs Having additional data that evolves over time as input to a stream operation For the glimpse at the far off future of Apache Flink we dare not make any predictions yet In the session we will look at the latest whisperings and see what the community is currently thinking up as solutions to existing problems and predicted future challenges in the stream processing space"},{"value":"Flink Forward 2016: Aljoscha Krettek -  The Future of Apache Flink"}],[{"value":"id:youtube:post:ACS6OM1-xgE"},{"value":"2016-09-20T08:47:24.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions robust stream processing with apache flink In this hands on talk and demonstration I’ll give a very short introduction to stream processing and then dive into writing code and demonstrating the features in Apache Flink that make truly robust stream processing possible We’ll focus on correctness and robustness in stream processing During this live demo we’ll be developing a realtime analytics application and modifying it on the fly based on the topics we’re working though We’ll exercise Flink’s unique features demonstrate fault recovery clearly explain and demonstrate why Event Time is such an important concept in robust stateful stream processing and talk about and demonstrate the features you need in a stream processor in production Some of the topics covered will be – Stateful Stream Processing – Event Time vs Processing Time – Fault tolerance – State management in the face of faults – Savepoints – Data re processing – Planned downtime and upgrades"},{"value":"Flink Forward 2016: Jamie Grier - Robust Stream Processing with Apache Flink"}],[{"value":"id:youtube:post:UrRQYzux5L0"},{"value":"2016-09-20T08:26:55.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"http flink forward org kb_sessions joining infinity windowless stream processing with flink The extensive set of high level Flink primitives makes it easy to join windowed streams However use cases that don’t have windows can prove to be more complicated making it necessary to leverage operator state and low level primitives to manually implement a continuous join This talk will focus on the anomalies that present themselves when performing streaming joins with infinite windows and the problems encountered operating topologies that back user facing data We will describe the approach taken at ResearchGate to implement and maintain a consistent join result of change data capture streams"},{"value":"Flink Forward 2016: Sanjar Akhmedov -  Joining Infinity: Windowless Stream Processing with Flink"}],[{"value":"id:youtube:post:ZBCXXiDr3TU"},{"value":"2016-03-01T14:16:52.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 2015 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Vasia Kalavri – Automatic Detection of Web Trackers"}],[{"value":"id:youtube:post:RgrJ3EcNIVo"},{"value":"2016-02-11T14:57:36.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Berlin Meetup 10 26 08 15 Large Scale Graph Processing with Apache Flink by Andra Lungu"},{"value":"26.08.15 Apache Flink Berlin Meetup #10 Andra Lungu"}],[{"value":"id:youtube:post:Rk8mVtGumPc"},{"value":"2016-02-11T14:57:34.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Berlin Meetup 13 26 01 16 Implementing BigPetStore by Márton Balassi"},{"value":"26.01.16  Apache Flink Berlin Meetup #13 Márton Balassi"}],[{"value":"id:youtube:post:P3zAw4quJ5k"},{"value":"2016-02-10T10:46:57.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Community Update Roadmap 2016 by Robert Metzger Berlin 26 01 2016"},{"value":"Apache Flink Meetup Berlin #13, 26.01.16 Community Update R. Metzger"}],[{"value":"id:youtube:post:4F4-ea1-v9o"},{"value":"2015-12-18T13:07:34.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Modern Effective Apache Mesos by Jörg Schad from Mesosphere"},{"value":"Apache Flink Meetup Berlin #12 Modern Effective Apache Mesos"}],[{"value":"id:youtube:post:1Y8zgLn1HTo"},{"value":"2015-12-18T12:48:43.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Comminity Update 16 12 2015 by Robert Metzger"},{"value":"Apache Flink Meetup Berlin #12 Community Update"}],[{"value":"id:youtube:post:Gs-Bl_HEY4A"},{"value":"2015-11-13T14:09:54.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Kostas Tzoumas & Stephan Ewen – Apache Flink: from incubation to Flink 1.0"}],[{"value":"id:youtube:post:y7f6wksGM6c"},{"value":"2015-11-13T13:31:08.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: William Vambenepe – Google Cloud Dataflow and Flink"}],[{"value":"id:youtube:post:r8sqwho6otY"},{"value":"2015-11-13T12:47:45.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Assaf Araki – Smart Data Pipes for the Internet of Things new"}],[{"value":"id:youtube:post:hJQr_9jb2qk"},{"value":"2015-11-13T12:28:21.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin Please note we had to re tape Kamals presentation due to a technical issue during recording"},{"value":"Flink Forward: Kamal Hakimzadeh – Karamel - Reproducing distributed systems and experiments on cloud"}],[{"value":"id:youtube:post:yozcWRyq2g4"},{"value":"2015-11-13T11:33:56.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Stefano Bortoli & Flavio Pompermaier – A Semantic Big Data Companion"}],[{"value":"id:youtube:post:SVnRFrEYE3s"},{"value":"2015-11-12T17:36:14.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Nam Luc Tran – Stale Synchronous Parallel Iterations on Flink"}],[{"value":"id:youtube:post:OHAv6o2fCi8"},{"value":"2015-11-12T16:32:22.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Slim Baltagi – Flink and Spark Similarities and Differences"}],[{"value":"id:youtube:post:GxnJ7m5NDNY"},{"value":"2015-11-12T16:32:17.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Marton Balassi – Stateful Stream Processing"}],[{"value":"id:youtube:post:Ef7LhYKftS8"},{"value":"2015-11-12T15:48:07.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Jim Dowling – Interactive Flink Analytics with Hopsworks and Apache Zeppelin"}],[{"value":"id:youtube:post:5ZgJquofKI4"},{"value":"2015-11-12T15:47:56.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Maximilian Michels – Training DataSet API Hands On and FlinkML"}],[{"value":"id:youtube:post:9t_nBkBgYn0"},{"value":"2015-11-12T15:47:45.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Aljoscha Krettek – Training DataStream API Hands On 2"}],[{"value":"id:youtube:post:T7hiwcwCXGI"},{"value":"2015-11-12T15:47:37.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Aljoscha Krettek – Training DataStream API Hands On 1"}],[{"value":"id:youtube:post:x_lR5wVxLHM"},{"value":"2015-11-12T15:04:43.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Fabian Hueske – Training Intro & System Setup"}],[{"value":"id:youtube:post:t7d_P7b8aFw"},{"value":"2015-11-12T11:40:38.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Vyacheslav Zholudev – Flink a convenient abstraction layer for YARN"}],[{"value":"id:youtube:post:cnqPyw_uQAQ"},{"value":"2015-11-12T11:40:38.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Christian Kreutzfeld – Static vs Dynamic Stream Processing"}],[{"value":"id:youtube:post:l0CmYzz1Oxg"},{"value":"2015-11-12T11:23:29.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Anwar Rizal – Implementing Streaming Decision Tree"}],[{"value":"id:youtube:post:QnvaxtCsAzs"},{"value":"2015-11-12T10:41:31.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Ignacio Mulas Viela – Applying Kappa Architecture in the Telecom Industry"}],[{"value":"id:youtube:post:hjmgZfXSi3M"},{"value":"2015-11-12T10:14:12.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Mohammed Amine – Real time data integration with Flink &  Kafka"}],[{"value":"id:youtube:post:8qptr8BJ4GQ"},{"value":"2015-11-11T14:46:52.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Michael Häusler – Everyday Flink"}],[{"value":"id:youtube:post:v_exWHj1vmo"},{"value":"2015-11-10T16:34:21.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Dongwon Kim – A comparative performance evaluation of Flink"}],[{"value":"id:youtube:post:ddVTZSNhCdo"},{"value":"2015-11-10T12:53:50.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Mikio Braun – Procedural Programming vs  Data Flow"}],[{"value":"id:youtube:post:xiKsOocNkDA"},{"value":"2015-11-09T13:54:22.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Aljoscha Krettek – Notions of Time"}],[{"value":"id:youtube:post:9M09bZ6TjcM"},{"value":"2015-11-09T10:59:13.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Fabian Hueske – Juggling with Bits and Bytes"}],[{"value":"id:youtube:post:UV6vP0IB17A"},{"value":"2015-11-09T10:59:11.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Till Rohrmann –  Fault Tolerance and Recovery of Flink Jobs"}],[{"value":"id:youtube:post:hRCE82J2fXE"},{"value":"2015-11-09T07:46:38.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Christopher Hillman – Beyond MapReduce, Scientific data processing in real time"}],[{"value":"id:youtube:post:an-rKMpTKR0"},{"value":"2015-11-09T07:45:50.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Alexander Kolb – Flink Yet another streaming framework"}],[{"value":"id:youtube:post:WmP9xB_sG2o"},{"value":"2015-11-06T16:13:13.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Martin Junghanns – Gradoop Scalable Graph Analytics with Apache Flink"}],[{"value":"id:youtube:post:c-L7R9WH2aM"},{"value":"2015-11-02T15:14:11.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 2015 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Ufuk Celebi – Apache Flink’s Streaming Data Flow"}],[{"value":"id:youtube:post:K3ugWmHb7CE"},{"value":"2015-11-01T18:41:16.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Maximilian Michaels – Google Cloud Dataflow on top of Apache Flink"}],[{"value":"id:youtube:post:aGQQkO83Ong"},{"value":"2015-11-01T18:40:15.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Matthias Sax – A tale of Squirrels and Storms"}],[{"value":"id:youtube:post:_Jf8yAy5WR8"},{"value":"2015-11-01T14:43:59.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: M. Schwering – Flink with MongoDB to enhance relevancy in personalization"}],[{"value":"id:youtube:post:G7JlpARrFkU"},{"value":"2015-11-01T12:55:56.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Fabian Hueske – Cascading on Flink"}],[{"value":"id:youtube:post:T6Er2ssAZFc"},{"value":"2015-10-31T18:27:53.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Suneel Marthi – BigPetStore A Comprehensive Blueprint for Apache Flink"}],[{"value":"id:youtube:post:icyOTyteMqs"},{"value":"2015-10-31T18:27:09.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Moon soo Lee – Data science lifecycle with Apache Flink and Apache Zeppelin"}],[{"value":"id:youtube:post:neEDkbRptNw"},{"value":"2015-10-31T18:26:08.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Albert Bifet – SAMOA Mining Big Data Streams with Apache Flink"}],[{"value":"id:youtube:post:Uh92PK0K0mA"},{"value":"2015-10-31T18:25:06.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Sebastian Schelter – Declarative Machine Learning with the Samsara DSL"}],[{"value":"id:youtube:post:CaObaAv9tLE"},{"value":"2015-10-31T09:15:26.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin"},{"value":"Flink Forward 2015: Simon Laws – Apache Flink cluster deployment on Docker using Docker Compose"}],[{"value":"id:youtube:post:J56z0YGYZ6w"},{"value":"2015-09-23T13:26:50.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 10 26 08 15 Slides can be found here http de slideshare net robertmetzger1 august flink community update"},{"value":"Apache Flink Meetup #10 Community Update by Robert Metzger 26.08.2015"}],[{"value":"id:youtube:post:hQEcVmKaaMs"},{"value":"2015-08-06T13:25:01.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup 9 29 07 2015 Find the slides here http de slideshare net AljoschaKrettek flink 010 upcoming features"},{"value":"Apache Flink Meetup #9 Upcoming Features – Aljoscha Krettek 29.07.2015"}],[{"value":"id:youtube:post:p-6oompVwjU"},{"value":"2015-08-06T12:23:17.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 9 29 07 15 Slides can be found here http de slideshare net robertmetzger1 flink cummunity update july berlin meetup"},{"value":"Apache Flink Meetup #9 Community Update by Robert Metzger 29.07.2015"}],[{"value":"id:youtube:post:mQes7I2QMUY"},{"value":"2015-07-09T13:12:32.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 8 23 06 15 Slides http www slideshare net MrtonBalassi flink communityupdatejune Blog http data artisans com flink at bouygues html Apache Flink Committer Marton Balassi gives the monthly Community Update at the eigth Apache Flink Meetup in Berlin https flink apache org http data artisans com"},{"value":"Apache Flink Community Update #8 by Marton Balassi 23.06.15"}],[{"value":"id:youtube:post:6BjoW2Vs2C0"},{"value":"2015-07-09T13:12:12.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Slides http de slideshare net mikiobraun flink meetup2015 Apache Flink meetup Berlin 23 06 15 Talk by Mikio Braun Data flow vs procedural programming How to put your algorithms into Flink Modern Big Data frameworks including Flink are often based on a data flow programming model The main data type is a set and an algorithm must be formulated in terms of transformations on these sets dealing with one element at a time This is in stark contrast to classical programming languages which are based on variables functions and control flow like for loops and conditional statements to process data Mikio will discuss both approaches and show how to translate a more classical piece of code into the data flow formalism to be able to benefit from the scalability of these systems https flink apache org http data artisans com"},{"value":"Data flow vs. procedural programming: How to put your algorithms into Flink  by Mikio Braun 23.06.15"}],[{"value":"id:youtube:post:YI3qdjKop3s"},{"value":"2015-06-03T22:26:02.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 27 05 15 Slides http www slideshare net fhueske how Blog post https flink apache org news 2015 05 A common challenge that all JVM based data analytics engines such as Apache Flink face is to store large amounts of data in memory to enable efficient sorting and joining The most straight forward approach to process on lots of data in a JVM is to put it as objects on the heap and operate on these objects However this approach has a few notable drawbacks In this talk Fabian will explain in detail how Flink actively manages its memory serializes objects into binary representations and efficiently operates on this data He will also show some numbers comparing the performance of sorting objects on the heap and sorting them in a serialized format https flink apache org http data artisans com"},{"value":"Juggling with Bits and Bytes - How Apache Flink operates on binary data - Fabian Hueske"}],[{"value":"id:youtube:post:UEkjRN8jRx4"},{"value":"2015-06-01T11:57:08.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 27 05 15 Slides http de slideshare net robertmetzger1 apache flink hands on Over the past years we ve seen many new Flink users In this talk Robert will answer the most frequent asked questions The talk is interesting for both new and existing Flink users New users will get a good overview of the system from a user s perspective and existing users will probably find some hidden gems in the talk"},{"value":"Hands on Apache Flink by Robert Metzger"}],[{"value":"id:youtube:post:9-FyOPoZ-VY"},{"value":"2015-05-28T17:08:22.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 7 27 05 15 Slides http de slideshare net robertmetzger1 berlin apache flink meetup may 2015 community update Apache Flink Committer Robert Metzger gives his monthly Community Update at the seventh Apache Flink Meetup in Berlin https flink apache org http data artisans com"},{"value":"Apache Flink Community Update #7 by Robert Metzger"}],[{"value":"id:youtube:post:oSCOf0lgRQI"},{"value":"2015-05-02T16:36:27.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 6 29 04 15 Slides http www slideshare net ucelebi apache flink meetup berlin 6 unified batch stream processing in apache flink Apache Flink Committer Ufuk Celebi gives an overview of Flink s runtime Ufuk explains how Flink runs your programs and what happens internally giving a deeper understanding of Flink s low level internals and how you can tweak your programs to make the most out of it https flink apache org http data artisans com"},{"value":"Apache Flink's Unified Batch & Stream Processing by Ufuk Celebi"}],[{"value":"id:youtube:post:OcoYFFVNp1o"},{"value":"2015-05-02T16:36:06.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Slides http www slideshare net FrankMcSherry flink meetup Apache Flink Meetup Berlin 6 29 04 15 Frank surveys some recent research work from his experience with the Naiad project on extended dataflow models including those integrating streaming and iterative computation The material is not specific to Flink but it should be interesting for anyone looking to push the boundaries of dataflow computation https flink apache org"},{"value":"Hot Topics in Data Flow by Frank McSherry @ Apache Flink Meetup Berlin"}],[{"value":"id:youtube:post:kQR5Jfds3h4"},{"value":"2015-05-02T16:32:47.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"Apache Flink Meetup Berlin 6 29 04 15 Slides http www slideshare net robertmetzger1 flink communityupdate 47595784 Apache Flink Committer Robert Metzger gives his monthly Community Update at the sixth Apache Flink Meetup in Berlin https flink apache org http data artisans com"},{"value":"Apache Flink Community Update #6    29.04.15 by Robert Metzger"}],[{"value":"id:youtube:post:fw2DBE6ZiEQ"},{"value":"2015-04-01T19:01:27.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"31 03 15 Slides http www slideshare net stephanewen1 flink history roadmap and vision Apache Flink Committer Stephan Ewen gives a talk about Apache Flink s History and Vision during the Apache Flink Meetup in Berlin In April 2014 Flink back then called Stratosphere was proposed as an incubating project to the Apache Software Foundation Nine months later Flink graduated to an Apache top level project To commemorate one year of Flink 1 We first take a trip down memory lane and discuss what the Flink community has built during the last year in the Apache Software Foundation 2 We then discuss the roadmap for the Flink project for 2015 and current work in progress features such as the runtime refactoring to include intermediate results and streaming fault tolerance 3 Finally we discuss the greater vision and goals of the Flink project and how the current roadmap leads to realizing this vision https flink apache org http data artisans com"},{"value":"History and Vision of Apache Flink by Stephan Ewen"}],[{"value":"id:youtube:post:qyl2GiebsJ8"},{"value":"2015-04-01T18:26:11.000Z"},{"value":"id:youtube:UCY8_lgiZLZErZPF47a2hXMA"},{"value":"Apache Flink Berlin"},{"value":"31 03 15 Slides http www slideshare net robertmetzger1 apache flink community update march 2015 Apache Flink Committer Robert Metzger gives his monthly Community Update at the Apache Flink Meetup in Berlin https flink apache org http data artisans com"},{"value":"Apache Flink Community Update #5 by Robert Metzger"}]],"columnNames":[{"name":"id","index":0,"aggr":"sum"},{"name":"published","index":1,"aggr":"sum"},{"name":"id","index":2,"aggr":"sum"},{"name":"displayName","index":3,"aggr":"sum"},{"name":"content","index":4,"aggr":"sum"},{"name":"title","index":5,"aggr":"sum"}],"rows":[["id:youtube:post:RYoFwQFvC_g","2016-11-17T14:29:43.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Two days of conference One day of training More than 350 attendees from all over the globe over 40 international speakers 3 stages and lots of squirrels – At Flink Forward Berlin we’ve enjoyed three days full of exciting training sessions keynotes technical talks and panels It was the second Flink Forward organized by data Artisans and we want to thank you for trusting us and making next year’s conferences in San Francisco and Berlin a blast droidcon Berlin – http droidcon de Facebook https www facebook com dr Google+ https plus google com +dr Twitter https twitter com droidconDE Instagram https instagram com droid LinkedIn https www linkedin com gr XING https www xing com commun Find more information on all droidcons worldwide on http droidcon com","A taste of Flink Forward"],["id:youtube:post:inFPmLV6FPI","2016-09-27T15:38:10.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Jamie Grier Director of Applications Engineering at data Artisans talks about his work at data Artisans and the Apache Flink projects he is involved with","Interview with Jamie Grier, Director of Applications Engineering at data Artisans"],["id:youtube:post:TI-uQtB57D4","2016-09-27T15:31:11.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Márton Balassi Solutions Architect at Cloudera talks about his work and the Apache Flink community","Interview with Márton Balassi, Solutions Architect at Cloudera"],["id:youtube:post:LvFcTedwpiI","2016-09-27T15:23:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Gyula Fóra Data Warehouse Engineer at King talks about his work and the most exciting Flink features to come","Interview with Gyula Fóra, Data Warehouse Engineer at King"],["id:youtube:post:6uvrWMbZ6xQ","2016-03-23T09:40:41.000Z","id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ","Apache Syncope","http syncope tirasa net news apache syncope 2 0 0 dashboard html","Apache Syncope 2.0.0 Dashboard"],["id:youtube:post:-VMoF70hwSA","2016-09-27T15:19:36.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Ted Dunning Chief Application Architect at MapR Technologies talks about his work and his first involvement in Apache Flink","Interview with Ted Dunning, Chief Application Architect at MapR Technologies"],["id:youtube:post:ARJLp6xhKo8","2016-09-27T15:11:45.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Maxim Fateev staff engineer at Uber talks about his projects at Uber and his experiences with Apache Flink","Interview with Maxim Fateev, staff engineer at Uber"],["id:youtube:post:xxKzjV2vmSA","2015-10-12T15:14:02.000Z","id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ","Apache Syncope","http syncope tirasa net news apache syncope 2 0 0 and swagger html","Apache Syncope 2.0.0 and Swagger UI"],["id:youtube:post:vl7Q2lKyPn8","2015-08-13T10:48:25.000Z","id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ","Apache Syncope","http syncope tirasa net news apache syncope 2 0 resource management html","Apache Syncope console 2.0 - Work in progress"],["id:youtube:post:EAFsq7QwFAc","2016-09-26T12:50:50.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Aljoscha Krettek stepped in for Robert Metzger http flink forward org kb_sessions connecting apache flink with the world reviewing the streaming connectors Getting data in and out of Flink in a reliable fashion is one of the most important tasks of a stream processor This talk will review the most important and frequently used connectors in Flink Apache Kafka and Amazon Kinesis Streams both fall into the same category of distributed high throughput and durable publish subscribe messaging systems The talk will explain how the connectors in Flink for these systems are implemented In particular we’ll focus on how we ensure exactly once semantics while consuming data and how offsets sequence numbers are handled We will also review two generic tools in Flink for connectors A message acknowledging source for classical message queues like those implementing AMQP and a generic write ahead log sink using Flink’s state backend abstraction The objective of the talk is to explain the internals of the streaming connectors so that people can understand their behavior configure them properly and implement their own connectors","Flink Forward 2016: Aljoscha Krettek - Connecting Apache Flink to the World..."],["id:youtube:post:2MWn7DlCfjY","2014-05-28T13:03:36.000Z","id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ","Apache Syncope","","Syncope Compliance Dashboard - Connectors Status"],["id:youtube:post:e-9Z_213_ZU","2016-09-26T12:37:24.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions to petascale and beyond apache flink in the clouds Apache Flink performs with low latency but can also scale to great heights Gelly is Flink s laboratory for building and tuning scalable graph algorithms and analytics In this talk we ll discuss writing algorithms optimized for the Flink architecture assembling and configuring a cloud compute cluster and boosting performance through benchmarking and system profiling This talk will cover recent developments in the Gelly library to include scalable graph generators and a mixed collection of modular algorithms written with native Flink operators We ll think like a data stream keep a cool cache and send the garbage collector on holiday To this we ll add a lightweight benchmarking harness to stress and validate core Flink and to identify and refactor hot code with aplomb","Flink Forward 2016: Greg Hogan -To Petascale and Beyond: Apache Flink in the Clouds"],["id:youtube:post:ahgu59FqhrM","2014-05-28T12:58:32.000Z","id:youtube:UCkrSQVb5Qzb13crS1kCOiQQ","Apache Syncope","","Syncope Compliance Dashboard - Architecture Overview"],["id:youtube:post:L21N8mNtvME","2016-09-26T12:32:07.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions multi tenant flink as a service on yarn Since June 2016 Flink as a service has been available to researchers and companies in Sweden from the Swedish ICT SICS Data Center at www hops site using the HopsWorks platform Flink applications can be either deployed as jobs batch or streaming or written and run directly from Apache Zeppelin on YARN Flink applications are run within a project on a YARN cluster with the novel property that Flink applications are metered and charged to projects Projects are also securely isolated from each other and include support for project specific Kafka topics that are protected from access by users that are not members of the project Hopsworks is entirely UI driven is open source and Flink applications that include Kafka topics can be created in a few mouse clicks In this talk we will discuss the challenges in building a metered version of Flink as a Service for YARN experiences with Flink on YARN and some of the possibilities that Hopsworks opens up for building secure multi ten","Flink Forward 2016: Jim Dowling - Multi-tenant Flink-as-a-Service on YARN"],["id:youtube:post:uscx9MrSKWY","2016-09-26T12:17:12.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions code generation in serializers and comparators of apache flink Performance of Big Data applications are often limited by serializers and comparators In the case of Flink despite its delicate type system hand writing serializers leads to a 10 improvement for a simple WordCount job using Pojos There are applications where the gain can be even more about 30 A significant amount of the overhead is the result of using reflection to access the fields of Pojo objects There is some additional overhead due to the fact that the JVM has a hard time to optimize the current default serializers and comparators because of their dynamic nature In order to improve the performance I implemented runtime code generation to generate specialized code for each Pojo type at runtime to improve the performance The generated code accesses fields without reflection and easier to optimize In the talk I will give a detailed overview of the challenges of implementing code generation the solutions and some measurements about the performance improvements","Flink Forward 2016: Gábor Horváth - Code Generation in Serializers and Comparators of Apache Flink"],["id:youtube:post:BZJnNfSBdQ8","2016-09-26T12:11:01.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions flink security enhancements Recent security enhancements to Flink make it easy to access secure data and to protect the associated credentials In this talk we’ll describe and demonstrate the new features including Kerberos based access to HDFS and Kafka transport security TLS and service level authorization which protects your Flink cluster from unauthorized access","Flink Forward 2016: Eron Wright -  Flink Security Enhancements"],["id:youtube:post:nXQvBy_onfs","2016-09-26T12:10:47.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions introducing flink on mesos Apache Flink supports a variety of deployment modes with support for Apache Mesos new to Flink 1 2 This talk will cover the benefits and major features of Flink on Mesos We’ll demonstrate the functionality and discuss future directions","Flink Forward 2016: Eron Wright - Introducing Flink on Mesos"],["id:youtube:post:TKcnMA7fn-s","2016-09-26T12:08:01.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions taking a look under the hood of apache flinks relational apis Apache Flink features two APIs which are based on relational algebra a SQL interface and the so called Table API which is a LINQ style API available for Scala and Java Relational APIs are interesting because they are easy to use and queries can be automatically optimized and translated into efficient runtime code Flink offers both APIs for streaming and batch data sources This talk will take a look under the hood of Flink’s relational APIs We will show the unified architecture to handle streaming and batch queries and explain how Flink translates queries of both APIs into the same representation leverages Apache Calcite to optimize them and generates runtime code for efficient execution Finally we will discuss potential improvements and give an outlook for future extensions and features","Flink Forward 2016: Fabian Hueske - Taking a look under the hood of Apache Flink’s relational APIs"],["id:youtube:post:vws5bv3XdD8","2016-09-26T12:06:31.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions declarative stream processing with streamsql and cep Complex event processing CEP and stream analytics are commonly treated as distinct classes of stream processing applications While CEP workloads identify patterns from event streams in near real time stream analytics queries ingest and aggregate high volume streams Both types of use cases have very different requirements which resulted in diverging system designs CEP systems excel at low latency processing whereas engines for stream analytics achieve high throughput Recent advances in open source stream processing yielded systems that can process several millions of events per second at sub second latency Systems like Apache Flink enable applications that include typical CEP features as well as heavy aggregations In this talk we will show how Apache Flink unifies CEP and stream analytics workloads Guided by examples we introduce Flink’s CEP enriched StreamSQL interface and discuss how queries are compiled optimized and executed on Flink","Flink Forward 2016: Fabian Hueske & Till Rohrmann - Declarative stream processing..."],["id:youtube:post:uuv-lnOrD0o","2016-09-26T11:06:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions the stream processor as a database building online applications directly on streams We present a new design pattern for data streaming applications using Apache Flink and Apache Kafka Building applications directly on top of the stream processor rather than on top of key value databases populated by data streams Unlike classical setups that use stream processors or libraries to pre process aggregate events and update a database with the results this setup simply gives the role of the database to the stream processor here Apache Flink routing queries to its workers who directly answer them from their internal state computed over the log of events Apache Kafka This talk will cover both the high level introduction to the architecture the techniques in Flink Kafka that make this approach possible as well as experiences from a large scale setup and technical details","Flink Forward 2016: Jamie Grier - The Stream Processor as a Database"],["id:youtube:post:3ySKJN5bbjk","2016-09-26T10:45:41.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions dynamic scaling how apache flink adapts to changing workloads Modern stream processing engines not only have to process millions of events per second at sub second latency but also have to cope with constantly changing workloads Due to the dynamic nature of stream applications where the number of incoming events can strongly vary with time systems cannot reliably predetermine the amount of required resources In order to meet guaranteed SLAs as well as utilizing system resources as efficiently as possible frameworks like Apache Flink have to adapt their resource consumption dynamically In this talk we will take a look under the hood and explain how Flink scales stateful application in and out Starting with the concept of key groups and partionable state we will cover ways to detect bottlenecks in streaming jobs and discuss efficient strategies how to scale out operators with minimal down time","Flink Forward 2016: Till Rohrmann - Dynamic Scaling - How Apache Flink adapts to changing workloads"],["id:youtube:post:17tUR4TsvpM","2016-09-26T10:33:49.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions rbea scalable real time analytics at king This talk introduces RBEA Rule Based Event Aggregator the scalable real time analytics platform developed by King’s Streaming Platform team We have built RBEA to make real time analytics easily accessible to game teams across King without having to worry about operational details RBEA is built on top of Apache Flink and uses the framework s capabilities to it s full potential in order to provide highly scalable stateful and windowed processing logic for the analytics applications We will talk about how we have built a high level DSL on the abstractions provided by Flink and how we tackled different technical challenges that have come up while developing the system","Flink Forward 2016: Gyula Fóra - RBEA- Scalable Real-Time Analytics at King"],["id:youtube:post:udQcdwa8jbg","2016-09-26T10:22:08.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions flink in zalandos world of microservices In this talk we present Zalando s microservices architecture introduce Saiki – our next generation data integration and distribution platform on AWS and show how we employ stream processing with Apache Flink for near real time business intelligence Zalando is one of the largest online fashion retailers in Europe In order to secure our future growth and remain competitive in this dynamic market we are transitioning from a monolithic to a microservices architecture and from a hierarchical to an agile organization We first have a look at how business intelligence processes have been working inside Zalando for the last years and present our current approach Saiki It is a scalable cloud based data integration and distribution infrastructure that makes data from our many microservices readily available for analytical teams We no longer live in a world of static data sets but are instead confronted with endless streams of events that constantly inform us about relevant happenings from all over the enterprise The processing of these event streams enables us to do near real time business intelligence In this context we have evaluated Apache Flink vs Apache Spark in order to choose the right stream processing framework Given our requirements we decided to use Flink as part of our technology stack alongside with Kafka and Elasticsearch With these technologies we are currently working on two use cases a near real time business process monitoring solution and streaming ETL Monitoring our business processes enables us to check if technically the Zalando platform works It also helps us analyze data streams on the fly e g order velocities delivery velocities and to control service level agreements On the other hand streaming ETL is used to relinquish resources from our relational data warehouse as it struggles with increasingly high loads In addition to that it also reduces the latency and facilitates the platform scalability Finally we have an outlook on our future use cases e g near real time sales and price monitoring Another aspect to be addressed is to lower the entry barrier of stream processing for our colleagues coming from a relational database background","Flink Forward 2016: Javier Lopez & Mihail Vieru - Flink in Zalando's World of Microservices"],["id:youtube:post:X83rmmb6rgs","2016-09-26T10:06:56.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions apache beam a unified model for batch and streaming data processing Unbounded unordered global scale datasets are increasingly common in day to day business and consumers of these datasets have detailed requirements for latency cost and completeness Apache Beam incubating defines a new data processing programming model that evolved from more than a decade of experience within Google including MapReduce FlumeJava MillWheel and Cloud Dataflow Beam handles both batch and streaming use cases and neatly separates properties of the data from runtime characteristics allowing pipelines to be portable across multiple runtimes both open source e g Apache Flink Apache Spark et al and proprietary e g Google Cloud Dataflow This talk will cover the basics of Apache Beam touch on its evolution describe main concepts in the programming model and compare with similar systems We’ll go from a simple scenario to a relatively complex data processing pipeline and finally demonstrate execution of that pipeline on multiple runtimes","Flink Forward 2016: Kenneth Knowles -  Apache Beam: A Unified Model for..."],["id:youtube:post:msdjh6KRXC8","2016-09-26T09:50:21.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions flink and beam current state roadmap It is no secret that the Dataflow model which evolved from Google’s MapReduce Flume and MillWheel has been a major influence to Apache Flink’s streaming API The essentials of this model are captured in Apache Beam Beam provides the Dataflow API with the option to deploy to various backends e g Flink Spark In this talk we will examine the current state of the Flink Runner Beam’s Runners manage the translation of the Beam API into the backend API The Beam project itself has made an effort to summarize the capabilities of each Runner to provide an overview of the supported API concepts From all open sources backends Flink is currently the Runner which supports the most features We will look at the supported Beam features and their counterpart in Flink Further we will look at potential improvements and upcoming features of the Flink Runner","Flink Forward 2016: Maximilian Michels - Flink and Beam: Current State & Roadmap"],["id:youtube:post:q9MPTCpWmuM","2016-09-26T09:27:08.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions no shard left behind dynamic work rebalancing in apache beam The Apache Beam incubating programming model is designed to support several advanced data processing features such as autoscaling and dynamic work rebalancing In this talk we will first explain how dynamic work rebalancing not only provides a general and robust solution to the problem of stragglers in traditional data processing pipelines but also how it allows autoscaling to be truly effective We will then present how dynamic work rebalancing works as implemented in Google Cloud Dataflow and which path other Apache Beam runners link Apache Flink can follow to benefit from it","Flink Forward 2016: Malo Denielou – No shard left behind: Dynamic work rebalancing in Apache Beam"],["id:youtube:post:YsWwox7Lnco","2016-09-26T09:07:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions flink in genomics efficient and scalable processing of raw illumina bcl data A single run in genome sequencing can easily produce several terabytes of data which subsequently feed a complex pipeline of tools Typically the first step in this workflow is a rearrangement of data roughly equivalent to a matrix transposition to reconstruct the original DNA fragments from the raw BCL data where the fragments are sliced and scattered over multiple files This step is followed by the sorting of the fragments by a specific identifying tag sequence which is attached during the preparation of the sample In this talk we will present a parallel program which performs these essential operations Our BCL converter is shown to have comparable performance to the shared memory Illumina bcl2fastq tool while also enabling easy and scalable distributed memory parallelization We will describe the techniques we have used to achieve high performance and discuss the features of Flink which we have particularly appreciated as well as the ones which we think are still missing","Flink Forward 2016 - Francesco Versaci - Flink in genomics..."],["id:youtube:post:OeHSPPWLeYQ","2016-09-26T08:41:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions building a real time tweet map with flink in six weeks It is often necessary to build a proof of concept for a bigdata project to show the feasibility to customers With OSTMap Open Source Tweet Map we proved that it is possible to accomplish this with the right choice of technologies in a short time frame OSTMap enables the user to view live geotagged tweets of the last hours on a map search all collected tweets by a term or user name and view the amount of incoming tweets per minute distinguished by language as a graph With OSTMap we cover several important areas of a typical big data PoC project scalability stream processing and ingest of incoming data batch processing of stored data performant queries on the data and visualization of the data To achieve this we use Apache Flink and Apache Accumulo as backend technologies AngularJS and Leaflet for the frontend OSTMap was developed iteratively using the walking skeleton approach which allowed us to increase the feature set constantly even with a strict deadline","Flink Forward 2016 - Matthias Kricke, Martin Grimmer, Michael Schmeißer – Building a real time..."],["id:youtube:post:k5pvgZUbIZA","2016-09-26T08:27:49.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions advanced visualization of flink and spark jobs Understanding the physical plan of a big data application is often crucial for tracking down bottlenecks and faulty behavior Flink and Spark although offering useful Web UI components for monitoring and understanding the logical plan of the jobs both lack a tool that helps to understand the physical plan of the scheduler and the possibility to monitor execution at a very low level along with the communication that occur between parallel vertex instances We propose a tool that allows users to real time monitor and later to replay examine job executions on any cluster currently supported by Flink or Spark The tool also offers monitoring of the distribution of keys in a data stream and can lead to optimizing data partitioning across parallel subtasks in the future","Flink Forward 2016: Zoltán Zvara - Advanced visualization of Flink and Spark jobs"],["id:youtube:post:-iWEnSJ_zaQ","2016-09-25T16:23:12.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions faster and furiouser flink drift Not long ago we had the opportunity to test Apache Flink to see just how fast it would go on a moderately realistic task with fast hardware and with a good streaming transport layer underneath Our goal was not so much careful comparison with other software but flat out speed Flink against Flink In the process we learned a lot about what it takes to go fast Some of the lessons were ones that we had “learned” a number of times before – the bottleneck isn’t where you thought it was – copying data is expensive – context switches are expensive – measure twice cut once But there were some real surprises along the way The really important knobs weren’t quite what people say you should turn One of the biggest surprises was the degree to which high performance libraries have threading built into them which makes the actual concurrrency much higher than the apparent concurrency The result was that at least one cluster parameter needed to be adjusted by 30x to get real","Flink Forward 2016: Ted Dunning - Faster and Furiouser: Flink Drift"],["id:youtube:post:oVDSi30U7rw","2016-09-25T14:19:25.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions apache zeppelin a friendlier way to flink In this talk we present Apache Zeppelin notebook based web UI for working with several big data platforms including Flink In this talk we will show how to leverage several of Zeppelin’s exciting features using Flink The talk demo will be a series of examples of increasing complexity Starting with the obligatory word count example we will move on to loading additional jars to perform machine learning tasks using FlinkML we will do some examples of graph processing in Gelly and visualizing those graphs using AngularJS and d3js both native to Zeppelin give examples of how Zeppelin’s “ResourcePools” can be used to share variables between interpreters leading in to a Flink Streaming Example where variables a “bound” and visualizations update in real time pre supposes working stable Flink Streaming in REPL editors feel free to delete this comment once that has been achieved","Flink Forward 2016: Trevor Grant -  Apache Zeppelin: A friendlier way to Flink"],["id:youtube:post:FtzXOLhZ-2c","2016-09-25T11:52:36.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions streaming ml with flink As continuous big data processing is gaining popularity it naturally implies that there is a need to transition many of the distributed machine learning functionality to a streaming backend The most common use case is to give streaming predictions based on the model learnt in batch however in some cases it is beneficial to also update the model on the fly It is not uncommon that streaming learners need different algorithms than their batch counterparts The talk discusses the common use cases and the pitfalls of the streaming ML transition through the example of recommender systems It also offer a dive into the implementation of a Scala library augmenting FlinkML with streaming predictors","Flink Forward 2016: Márton Balassi - Streaming ML with Flink"],["id:youtube:post:k8RIjuwqIds","2016-09-25T09:36:51.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions streaming sql Streaming is necessary to handle data rates and latency but SQL is unquestionably the lingua franca of data Is it possible to combine SQL with streaming and if so what does the resulting language look like Apache Calcite is extending SQL to include streaming and Apache Flink is using Calcite to support both regular and streaming SQL In this talk Julian Hyde describes streaming SQL in detail and shows how you can use streaming SQL in your application He also describes how Calcite’s planner optimizes queries for throughput and latency","Flink Forward 2016: Julian Hyde - Streaming SQL"],["id:youtube:post:rbvTVQNY8UQ","2016-09-25T07:46:47.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions panel large scale streaming in production As stream processing systems become more mainstream companies are looking to empower their users to take advantage of this technology Stream processing systems promise to allow users to gain valuable data insights in realtime and to simplify and improve common data processing and analytics tasks The scale of stream processing systems can be measured along several dimensions We will focus on two of them in this session The first dimension is data velocity Millions of messages per second is common for some workloads The second dimension is user base Those implementing stream processing systems need to support large and diverse user populations In this session we will have leading experts in the field talk about the challenges they have faced and the solutions they have discovered while implementing stream processing systems at very large scales We will cover the motivations behind these systems discuss the various user groups they serve and discuss the major challenges that need to be addressed Panelists Maxim Fateev Xiaowei Jiang Monal Daxini Ted Dunning Moderated by Jamie Grier","Flink Forward: Panel: Large Scale Streaming in Production"],["id:youtube:post:n679Xa3ZrFo","2016-09-24T17:00:15.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions keynote tba Apache Flink has come a long way from its academic beginnings It is now one of the most technically advanced solutions for streaming computation And batch computation too Flink has serious technical advantages when compared with nearly every alternative system This success ironically means that Apache Flink is right on the cusp of a critical moment Over the next few months it will be decided whether Flink is the Next Big Thing or if it is a fine technology with limited impact Right now what you and I do can make a huge difference But as business people like to say what got Flink here isn’t what’s going to get it there The challenges the Flink community faces now are different from the technical challenges it has met so far I will talk about what I think will help and how we can all pitch in to take Flink forward","Flink Forward 2016: Ted Dunning - Keynote: How Can We Take Flink Forward?"],["id:youtube:post:NI1yN5FbxUM","2016-09-24T12:09:21.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions keynote tba 2 The past 12 months saw the data streaming ecosystem mature and grow tremendously with new open source projects and products being offered in the market and more large scale production applications of streaming data It is now understood that streaming data is not a fad but a growing industry that is here to stay Apache Flink was one of the pioneering communities advocating that stream processing is a great fit for the continuous nature of data production and that batch processing can be seen and efficiently performed as a special case of stream processing Flink saw tremendous growth since the last Flink Forward conference with the project boasting now more than 200 contributors from several companies several production installations and broad adoption In this talk we discuss several large scale stream processing use cases that we see at data Artisans Additionally we discuss what this accelerated growth means for Flink how we can sustain this growth moving forward as well as a vision for the next big directions in Flink","Flink Forward 2016: Kostas Tzoumas & Stephan Ewen - Keynote"],["id:youtube:post:Jexh_GsSWWs","2016-09-20T11:14:10.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","","Kostas Tzoumas - Closing Session"],["id:youtube:post:B2b5qMHA2GI","2016-09-20T11:10:32.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions flinkspector taming the squirrel The costs of logic errors in production for streaming applications are higher than for batch processing systems Depending on the setup errors cannot be rectified or have already influenced important decisions The goal of Flinkspector is to improve the test process of Apache Flink streaming applications in order to detect streaming application logic errors early during development It features dedicated mechanics for test setup execution and evaluation While Flinkspector s streamlined API keeps testing overhead small The framework is able to handle non terminating and parallelized data flows involving windowing The lightweight integration tests enabled by Flinkspector allow Flink applications to be included into the continuous integration and deployment process The talk introduces the core functionality of Flinkspector In addition background concepts of the runtime and the evaluation algorithms are presented https github com ottogroup flink spector","Flink Forward 2016: Alexander Kolb - Flinkspector: Taming the squirrel"],["id:youtube:post:zlU1h0SV4SQ","2016-09-20T10:52:47.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions large scale social network data collection and analysis with apache flink and apache streams Apache Flink offers unparalleled powered and control for streaming applications at scale wrapped in developer friendly Java and Scala SDKs simple to scale up and monitor even for high throughput applications It’s a beast an adorable beast hungry for data and we must feed it Apache Streams incubating unifies a diverse world of digital profiles and online activities into common formats and vocabularies and makes these datasets accessible through standard interfaces hiding the complexity of the underlying APIs and making the data they generate inter compatible by default Streams is the perfect tool to ingest interesting datasets to feed Flink and embedding Streams components within Flink pipelines is dead simple and downright pleasant People Pattern uses Flink and Streams to grow and maintain our database of profiles 200M and growing plus posts and connections from 10+ social networking services including Twitter Instagram Google+ Come learn how we do it","Flink Forward 2016: Steve Blackmon - Large Scale Social Network Data Collection & Analysis..."],["id:youtube:post:uXMmOjFBa94","2016-09-20T10:38:51.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions evaluating streaming framework performance for a large scale aggregation pipeline In this talk I present the results of a set of experiments comparing the performance of several implementations of aggregating time series data There are 3 implementations a baseline implementation not using any streaming frameworks an implementation using Apache Flink and an implementation using Apache Spark Streaming These implementations all ran against the same Kafka cluster using the same data stream with the goal to understand the limitations of the different implementations The limitations were measured at 3 input data rates 100 6000 and breaking point load","Flink Forward 2016: Ron Crocker - Evaluating Streaming Framework Performance for a Large-Scale..."],["id:youtube:post:9mjAPBNl4YM","2016-09-20T10:26:57.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions beyond the watermark on demand backfilling in flink Flink has consistency guarantees and efficient checkpointing model which make it a good fit for Uber’s money related use cases such as driver incentives However Flink’s time progress model is built around a single watermark which is incompatible with Uber’s business need for generating aggregates retroactively The talk covers our solution for on demand backfilling It also outlines other abstractions and features we expect Flink to support as it matures","Flink Forward 2016: Maxim Fateev - Beyond the Watermark: On-Demand Backfilling in Flink"],["id:youtube:post:RvgXt-PIGyI","2016-09-20T10:10:29.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions amidst toolbox scalable probabilistic machine learning with flink In this session we would like to present our AMIDST toolbox for analysis of large scale data sets using probabilistic machine learning models AMIDST runs algorithms in a distributed fashion for learning and inference in a wide spectrum of latent variable models such as Gaussian mixtures probabilistic principal component analysis Hidden Markov Models Kalman Filters Latent Dirichlet Allocation etc This toolbox is able to perform Bayesian parameter learning on any user defined probabilistic graphical model with billions of nodes using novel distributed message passing algorithms We plan to give an overview of the AMIDST toolbox Java open source some details about the API and the integration with Flink and an analysis of the scalability of our learning algorithms All this in the context of a real use case scenario in the financial domain BCC group where the profile of millions of customers is analyzed using Flink and the Amazon Web Services","Flink Forward 2016: Ana M. Martinez - AMIDST Toolbox: Scalable probabil. machine learning w/ Flink"],["id:youtube:post:izYsMQWeUbE","2016-09-20T10:00:35.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions a brief history of time with apache flink real time monitoring and analysis with flink kafka hb Many use cases in the telecommunication industry require producing counters quality metrics and alarms in a streaming fashion with very low latency Most of this metrics are only valuable when they’re made available as soon as the associated events happened In our company we are looking for a system able to produce this kind of real time indicator which must handle massive amounts of data 400 000 eps with often peak loads like New Year’s Eve or out of order events like massive network disorder Low latency and flexible window management with specific watermark emission are also a must haves Heterogeneous format multiple flow correlation and the possibility of late data arrival are other challenges Flink being already widely used at Bouygues Telecom for real time data integration its features made it the evident candidate for the future System In this talk we’ll present a real use case of streaming analytics using Flink Kafka HBase along with other legacy systems","Flink Forward 2016: Mohamed ABDESSEMED & T. Lamirault - A brief history of time with Apache Flink"],["id:youtube:post:_qWs_rMUKPQ","2016-09-20T09:57:21.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions running apache flink everywhere standalone yarn mesos docker kubernetes etc The world of cluster managers and deployment frameworks is getting complicated There is zoo of tools to deploy and manage data processing jobs all of which have different resource management and fault tolerance slightly different Some tools have a only per job processes Yarn Docker Kubernetes while others require some long running processes Mesos Standalone In some frameworks streaming jobs control their own resource allocation Yarn Mesos while for other frameworks resource management is handled by external tools Kubernetes To be broadly usable in a variety of setups Flink needs to play well with all these frameworks and their paradigms This talk describes Flink s new proposed process and deployment model that will make it work together well with the above mentioned frameworks The new abstraction is designed to cover a variety of use cases like isolated single job deployments sessions of multiple short jobs and multi tenant setups","Flink Forward 2016: Stephan Ewen - Running Apache Flink everywhere"],["id:youtube:post:w9f-440oejg","2016-09-20T09:37:54.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions blink improvements to flink and its application in alibaba search A large portion of transactions on Alibaba’s e commerce Taobao platform is initiated through its Alibaba Search engine Real time data streaming processing is one of the cornerstones in Alibaba’s search infrastructure Among all the streaming solutions Flink is the closest to meet our requirements However we don’t think Flink is quite up to our scale and reliability challenges For example its current support for Yarn can result in inefficiency in resource allocation Job isolation and debugging can also be challenging In this paper we present the design and implementation of Blink an improved runtime engine for Flink better integrated with Yarn It addresses above and various other problems we encountered in production Since the changes are at the runtime layer Blink is fully compatible with the Flink API and its machine learning libraries We will also share the experience in our production use in a Hadoop cluster of more than one thousand servers in Alibaba Search","Flink Forward 2016: Xiaowei Jiang - Blink: Improvements to Flink & its application in Alibaba Search"],["id:youtube:post:RJ3JNpzI9vk","2016-09-20T09:20:36.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions beaming flink to the cloud netflix Netflix is a data driven company and we process over 700 billion streaming events per day with at least once processing semantics in the cloud To enable extracting intelligence from this unbounded stream easily we are building Stream Processing as a Service SPaaS infrastructure so that the user can focus on extracting value and not have to worry about boilerplate infrastructure and scale We will share our experience in building a scalable SPaaS using Flink Apache Beam and Kafka as the foundation layer to process over 1 3 PB of event data without service disruption","Flink Forward 2016: Monal Daxini - Beaming Flink to the Cloud @ Netflix"],["id:youtube:post:oPorLtfOB4o","2016-09-20T09:06:11.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions the future of apache flinktm In this session we will first have a look at the current state of Apache Flink before diving into some of the upcoming features that are either already in development or still in the design phase Some of the features currently in development that we are going to cover are Dynamic Scaling Adapting a running program to changing workloads Queryable State External querying of internal Flink state This has the power to replace key value stores by turning Flink into a key value store that allows for up to date querying of results Side Inputs Having additional data that evolves over time as input to a stream operation For the glimpse at the far off future of Apache Flink we dare not make any predictions yet In the session we will look at the latest whisperings and see what the community is currently thinking up as solutions to existing problems and predicted future challenges in the stream processing space","Flink Forward 2016: Aljoscha Krettek -  The Future of Apache Flink"],["id:youtube:post:ACS6OM1-xgE","2016-09-20T08:47:24.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions robust stream processing with apache flink In this hands on talk and demonstration I’ll give a very short introduction to stream processing and then dive into writing code and demonstrating the features in Apache Flink that make truly robust stream processing possible We’ll focus on correctness and robustness in stream processing During this live demo we’ll be developing a realtime analytics application and modifying it on the fly based on the topics we’re working though We’ll exercise Flink’s unique features demonstrate fault recovery clearly explain and demonstrate why Event Time is such an important concept in robust stateful stream processing and talk about and demonstrate the features you need in a stream processor in production Some of the topics covered will be – Stateful Stream Processing – Event Time vs Processing Time – Fault tolerance – State management in the face of faults – Savepoints – Data re processing – Planned downtime and upgrades","Flink Forward 2016: Jamie Grier - Robust Stream Processing with Apache Flink"],["id:youtube:post:UrRQYzux5L0","2016-09-20T08:26:55.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","http flink forward org kb_sessions joining infinity windowless stream processing with flink The extensive set of high level Flink primitives makes it easy to join windowed streams However use cases that don’t have windows can prove to be more complicated making it necessary to leverage operator state and low level primitives to manually implement a continuous join This talk will focus on the anomalies that present themselves when performing streaming joins with infinite windows and the problems encountered operating topologies that back user facing data We will describe the approach taken at ResearchGate to implement and maintain a consistent join result of change data capture streams","Flink Forward 2016: Sanjar Akhmedov -  Joining Infinity: Windowless Stream Processing with Flink"],["id:youtube:post:ZBCXXiDr3TU","2016-03-01T14:16:52.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 2015 at Kulturbrauerei Berlin","Flink Forward 2015: Vasia Kalavri – Automatic Detection of Web Trackers"],["id:youtube:post:RgrJ3EcNIVo","2016-02-11T14:57:36.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Berlin Meetup 10 26 08 15 Large Scale Graph Processing with Apache Flink by Andra Lungu","26.08.15 Apache Flink Berlin Meetup #10 Andra Lungu"],["id:youtube:post:Rk8mVtGumPc","2016-02-11T14:57:34.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Berlin Meetup 13 26 01 16 Implementing BigPetStore by Márton Balassi","26.01.16  Apache Flink Berlin Meetup #13 Márton Balassi"],["id:youtube:post:P3zAw4quJ5k","2016-02-10T10:46:57.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Community Update Roadmap 2016 by Robert Metzger Berlin 26 01 2016","Apache Flink Meetup Berlin #13, 26.01.16 Community Update R. Metzger"],["id:youtube:post:4F4-ea1-v9o","2015-12-18T13:07:34.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Modern Effective Apache Mesos by Jörg Schad from Mesosphere","Apache Flink Meetup Berlin #12 Modern Effective Apache Mesos"],["id:youtube:post:1Y8zgLn1HTo","2015-12-18T12:48:43.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Comminity Update 16 12 2015 by Robert Metzger","Apache Flink Meetup Berlin #12 Community Update"],["id:youtube:post:Gs-Bl_HEY4A","2015-11-13T14:09:54.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Kostas Tzoumas & Stephan Ewen – Apache Flink: from incubation to Flink 1.0"],["id:youtube:post:y7f6wksGM6c","2015-11-13T13:31:08.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: William Vambenepe – Google Cloud Dataflow and Flink"],["id:youtube:post:r8sqwho6otY","2015-11-13T12:47:45.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Assaf Araki – Smart Data Pipes for the Internet of Things new"],["id:youtube:post:hJQr_9jb2qk","2015-11-13T12:28:21.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin Please note we had to re tape Kamals presentation due to a technical issue during recording","Flink Forward: Kamal Hakimzadeh – Karamel - Reproducing distributed systems and experiments on cloud"],["id:youtube:post:yozcWRyq2g4","2015-11-13T11:33:56.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Stefano Bortoli & Flavio Pompermaier – A Semantic Big Data Companion"],["id:youtube:post:SVnRFrEYE3s","2015-11-12T17:36:14.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Nam Luc Tran – Stale Synchronous Parallel Iterations on Flink"],["id:youtube:post:OHAv6o2fCi8","2015-11-12T16:32:22.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Slim Baltagi – Flink and Spark Similarities and Differences"],["id:youtube:post:GxnJ7m5NDNY","2015-11-12T16:32:17.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Marton Balassi – Stateful Stream Processing"],["id:youtube:post:Ef7LhYKftS8","2015-11-12T15:48:07.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Jim Dowling – Interactive Flink Analytics with Hopsworks and Apache Zeppelin"],["id:youtube:post:5ZgJquofKI4","2015-11-12T15:47:56.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Maximilian Michels – Training DataSet API Hands On and FlinkML"],["id:youtube:post:9t_nBkBgYn0","2015-11-12T15:47:45.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Aljoscha Krettek – Training DataStream API Hands On 2"],["id:youtube:post:T7hiwcwCXGI","2015-11-12T15:47:37.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Aljoscha Krettek – Training DataStream API Hands On 1"],["id:youtube:post:x_lR5wVxLHM","2015-11-12T15:04:43.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Fabian Hueske – Training Intro & System Setup"],["id:youtube:post:t7d_P7b8aFw","2015-11-12T11:40:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Vyacheslav Zholudev – Flink a convenient abstraction layer for YARN"],["id:youtube:post:cnqPyw_uQAQ","2015-11-12T11:40:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Christian Kreutzfeld – Static vs Dynamic Stream Processing"],["id:youtube:post:l0CmYzz1Oxg","2015-11-12T11:23:29.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Anwar Rizal – Implementing Streaming Decision Tree"],["id:youtube:post:QnvaxtCsAzs","2015-11-12T10:41:31.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Ignacio Mulas Viela – Applying Kappa Architecture in the Telecom Industry"],["id:youtube:post:hjmgZfXSi3M","2015-11-12T10:14:12.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Mohammed Amine – Real time data integration with Flink &  Kafka"],["id:youtube:post:8qptr8BJ4GQ","2015-11-11T14:46:52.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Michael Häusler – Everyday Flink"],["id:youtube:post:v_exWHj1vmo","2015-11-10T16:34:21.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Dongwon Kim – A comparative performance evaluation of Flink"],["id:youtube:post:ddVTZSNhCdo","2015-11-10T12:53:50.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Mikio Braun – Procedural Programming vs  Data Flow"],["id:youtube:post:xiKsOocNkDA","2015-11-09T13:54:22.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Aljoscha Krettek – Notions of Time"],["id:youtube:post:9M09bZ6TjcM","2015-11-09T10:59:13.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Fabian Hueske – Juggling with Bits and Bytes"],["id:youtube:post:UV6vP0IB17A","2015-11-09T10:59:11.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Till Rohrmann –  Fault Tolerance and Recovery of Flink Jobs"],["id:youtube:post:hRCE82J2fXE","2015-11-09T07:46:38.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Christopher Hillman – Beyond MapReduce, Scientific data processing in real time"],["id:youtube:post:an-rKMpTKR0","2015-11-09T07:45:50.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Alexander Kolb – Flink Yet another streaming framework"],["id:youtube:post:WmP9xB_sG2o","2015-11-06T16:13:13.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Martin Junghanns – Gradoop Scalable Graph Analytics with Apache Flink"],["id:youtube:post:c-L7R9WH2aM","2015-11-02T15:14:11.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 2015 at Kulturbrauerei Berlin","Flink Forward 2015: Ufuk Celebi – Apache Flink’s Streaming Data Flow"],["id:youtube:post:K3ugWmHb7CE","2015-11-01T18:41:16.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Maximilian Michaels – Google Cloud Dataflow on top of Apache Flink"],["id:youtube:post:aGQQkO83Ong","2015-11-01T18:40:15.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Matthias Sax – A tale of Squirrels and Storms"],["id:youtube:post:_Jf8yAy5WR8","2015-11-01T14:43:59.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: M. Schwering – Flink with MongoDB to enhance relevancy in personalization"],["id:youtube:post:G7JlpARrFkU","2015-11-01T12:55:56.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Fabian Hueske – Cascading on Flink"],["id:youtube:post:T6Er2ssAZFc","2015-10-31T18:27:53.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Suneel Marthi – BigPetStore A Comprehensive Blueprint for Apache Flink"],["id:youtube:post:icyOTyteMqs","2015-10-31T18:27:09.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Moon soo Lee – Data science lifecycle with Apache Flink and Apache Zeppelin"],["id:youtube:post:neEDkbRptNw","2015-10-31T18:26:08.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Albert Bifet – SAMOA Mining Big Data Streams with Apache Flink"],["id:youtube:post:Uh92PK0K0mA","2015-10-31T18:25:06.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Sebastian Schelter – Declarative Machine Learning with the Samsara DSL"],["id:youtube:post:CaObaAv9tLE","2015-10-31T09:15:26.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Flink Forward Conference on Apache Flink October 12 13 at Kulturbrauerei Berlin","Flink Forward 2015: Simon Laws – Apache Flink cluster deployment on Docker using Docker Compose"],["id:youtube:post:J56z0YGYZ6w","2015-09-23T13:26:50.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 10 26 08 15 Slides can be found here http de slideshare net robertmetzger1 august flink community update","Apache Flink Meetup #10 Community Update by Robert Metzger 26.08.2015"],["id:youtube:post:hQEcVmKaaMs","2015-08-06T13:25:01.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup 9 29 07 2015 Find the slides here http de slideshare net AljoschaKrettek flink 010 upcoming features","Apache Flink Meetup #9 Upcoming Features – Aljoscha Krettek 29.07.2015"],["id:youtube:post:p-6oompVwjU","2015-08-06T12:23:17.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 9 29 07 15 Slides can be found here http de slideshare net robertmetzger1 flink cummunity update july berlin meetup","Apache Flink Meetup #9 Community Update by Robert Metzger 29.07.2015"],["id:youtube:post:mQes7I2QMUY","2015-07-09T13:12:32.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 8 23 06 15 Slides http www slideshare net MrtonBalassi flink communityupdatejune Blog http data artisans com flink at bouygues html Apache Flink Committer Marton Balassi gives the monthly Community Update at the eigth Apache Flink Meetup in Berlin https flink apache org http data artisans com","Apache Flink Community Update #8 by Marton Balassi 23.06.15"],["id:youtube:post:6BjoW2Vs2C0","2015-07-09T13:12:12.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Slides http de slideshare net mikiobraun flink meetup2015 Apache Flink meetup Berlin 23 06 15 Talk by Mikio Braun Data flow vs procedural programming How to put your algorithms into Flink Modern Big Data frameworks including Flink are often based on a data flow programming model The main data type is a set and an algorithm must be formulated in terms of transformations on these sets dealing with one element at a time This is in stark contrast to classical programming languages which are based on variables functions and control flow like for loops and conditional statements to process data Mikio will discuss both approaches and show how to translate a more classical piece of code into the data flow formalism to be able to benefit from the scalability of these systems https flink apache org http data artisans com","Data flow vs. procedural programming: How to put your algorithms into Flink  by Mikio Braun 23.06.15"],["id:youtube:post:YI3qdjKop3s","2015-06-03T22:26:02.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 27 05 15 Slides http www slideshare net fhueske how Blog post https flink apache org news 2015 05 A common challenge that all JVM based data analytics engines such as Apache Flink face is to store large amounts of data in memory to enable efficient sorting and joining The most straight forward approach to process on lots of data in a JVM is to put it as objects on the heap and operate on these objects However this approach has a few notable drawbacks In this talk Fabian will explain in detail how Flink actively manages its memory serializes objects into binary representations and efficiently operates on this data He will also show some numbers comparing the performance of sorting objects on the heap and sorting them in a serialized format https flink apache org http data artisans com","Juggling with Bits and Bytes - How Apache Flink operates on binary data - Fabian Hueske"],["id:youtube:post:UEkjRN8jRx4","2015-06-01T11:57:08.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 27 05 15 Slides http de slideshare net robertmetzger1 apache flink hands on Over the past years we ve seen many new Flink users In this talk Robert will answer the most frequent asked questions The talk is interesting for both new and existing Flink users New users will get a good overview of the system from a user s perspective and existing users will probably find some hidden gems in the talk","Hands on Apache Flink by Robert Metzger"],["id:youtube:post:9-FyOPoZ-VY","2015-05-28T17:08:22.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 7 27 05 15 Slides http de slideshare net robertmetzger1 berlin apache flink meetup may 2015 community update Apache Flink Committer Robert Metzger gives his monthly Community Update at the seventh Apache Flink Meetup in Berlin https flink apache org http data artisans com","Apache Flink Community Update #7 by Robert Metzger"],["id:youtube:post:oSCOf0lgRQI","2015-05-02T16:36:27.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 6 29 04 15 Slides http www slideshare net ucelebi apache flink meetup berlin 6 unified batch stream processing in apache flink Apache Flink Committer Ufuk Celebi gives an overview of Flink s runtime Ufuk explains how Flink runs your programs and what happens internally giving a deeper understanding of Flink s low level internals and how you can tweak your programs to make the most out of it https flink apache org http data artisans com","Apache Flink's Unified Batch & Stream Processing by Ufuk Celebi"],["id:youtube:post:OcoYFFVNp1o","2015-05-02T16:36:06.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Slides http www slideshare net FrankMcSherry flink meetup Apache Flink Meetup Berlin 6 29 04 15 Frank surveys some recent research work from his experience with the Naiad project on extended dataflow models including those integrating streaming and iterative computation The material is not specific to Flink but it should be interesting for anyone looking to push the boundaries of dataflow computation https flink apache org","Hot Topics in Data Flow by Frank McSherry @ Apache Flink Meetup Berlin"],["id:youtube:post:kQR5Jfds3h4","2015-05-02T16:32:47.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","Apache Flink Meetup Berlin 6 29 04 15 Slides http www slideshare net robertmetzger1 flink communityupdate 47595784 Apache Flink Committer Robert Metzger gives his monthly Community Update at the sixth Apache Flink Meetup in Berlin https flink apache org http data artisans com","Apache Flink Community Update #6    29.04.15 by Robert Metzger"],["id:youtube:post:fw2DBE6ZiEQ","2015-04-01T19:01:27.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","31 03 15 Slides http www slideshare net stephanewen1 flink history roadmap and vision Apache Flink Committer Stephan Ewen gives a talk about Apache Flink s History and Vision during the Apache Flink Meetup in Berlin In April 2014 Flink back then called Stratosphere was proposed as an incubating project to the Apache Software Foundation Nine months later Flink graduated to an Apache top level project To commemorate one year of Flink 1 We first take a trip down memory lane and discuss what the Flink community has built during the last year in the Apache Software Foundation 2 We then discuss the roadmap for the Flink project for 2015 and current work in progress features such as the runtime refactoring to include intermediate results and streaming fault tolerance 3 Finally we discuss the greater vision and goals of the Flink project and how the current roadmap leads to realizing this vision https flink apache org http data artisans com","History and Vision of Apache Flink by Stephan Ewen"],["id:youtube:post:qyl2GiebsJ8","2015-04-01T18:26:11.000Z","id:youtube:UCY8_lgiZLZErZPF47a2hXMA","Apache Flink Berlin","31 03 15 Slides http www slideshare net robertmetzger1 apache flink community update march 2015 Apache Flink Committer Robert Metzger gives his monthly Community Update at the Apache Flink Meetup in Berlin https flink apache org http data artisans com","Apache Flink Community Update #5 by Robert Metzger"]]},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-19T00:00:10-0600","dateFinished":"2016-11-19T00:00:10-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:261"},{"title":"","text":"%md\n\nThanks for playing!\n","user":"anonymous","dateUpdated":"2016-11-19T00:41:39-0600","config":{"colWidth":12,"editorMode":"ace/mode/markdown","graph":{"mode":"table","optionOpen":false,"keys":[],"values":[],"scatter":{},"groups":[],"height":300},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479492141066_-630916770","id":"20161114-115156_1010107862","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Thanks for playing!</p>\n"},"dateCreated":"2016-11-18T19:02:21-0600","dateStarted":"2016-11-19T00:42:04-0600","dateFinished":"2016-11-19T00:42:04-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:262"},{"text":"%md\n","dateUpdated":"2016-11-19T00:41:39-0600","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1479512499545_1163706012","id":"20161119-004139_331088641","dateCreated":"2016-11-19T00:41:39-0600","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:263"}],"name":"YouTube","id":"2C3QJ2KXV","angularObjects":{"2C2Y5MR83:shared_process":[],"2C1GMAZQC:shared_process":[],"2C2MBD44C:shared_process":[],"2C2YXPWHY:shared_process":[],"2C2VHBCVU:shared_process":[],"2BYHC6ZD2:shared_process":[],"2C1D6ZA8S:shared_process":[],"2C1Z4DP38:shared_process":[],"2C2GHVYQJ:shared_process":[],"2BY753919:shared_process":[],"2BY8NRV4Y:shared_process":[],"2BZUCUEMD:shared_process":[],"2C1BUX3N1:shared_process":[],"2BYCU1N2S:shared_process":[],"2C294QED3:shared_process":[],"2C2DYX87W:shared_process":[],"2BZYRVV9U:shared_process":[],"2C2KZZJ6Z:shared_process":[],"2BZ8SQWBY:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}